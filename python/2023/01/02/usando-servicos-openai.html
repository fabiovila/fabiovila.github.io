<!DOCTYPE html>
<html lang="pt-BR">
    <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Primary Meta Tags -->
    <title>Usando os serviços OpenAI para criar um ChatBot - Python</title>
    <meta name="title" content="Usando os serviços OpenAI para criar um ChatBot - Python" />
    <meta name="description" content="" />
    

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="/python/2023/01/02/usando-servicos-openai.html" />
    <meta property="og:title" content="Usando os serviços OpenAI para criar um ChatBot - Python" />
    <meta property="og:description" content="Aprenda a fazer um chatbot usando os serviços da OpenAI."  />
    <meta property="og:image" content="/assets/imgs/1c1b1ada-54b5-41d8-abc9-4ad746983679.jpeg" />

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image" />
    <meta property="twitter:url" content="/python/2023/01/02/usando-servicos-openai.html" />
    <meta property="twitter:title" content="Usando os serviços OpenAI para criar um ChatBot - Python"  />
    <meta property="twitter:description" content="Aprenda a fazer um chatbot usando os serviços da OpenAI." />
    <meta property="twitter:image" content="/assets/imgs/1c1b1ada-54b5-41d8-abc9-4ad746983679.jpeg"/>

    <!-- Meta Tags Generated with https://metatags.io -->

    <link rel="preload"  href='/assets/css/style.css' as="style" type="text/css">
    <link rel="stylesheet"  href='/assets/css/style.css'>
    <link rel="stylesheet"  href='/assets/css/github.css'>
    <script rel="preload" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/js/all.min.js" integrity="sha512-6sSYJqDreZRZGkJ3b+YfdhB3MzmuP9R7X1QZ6g5aIXhRvR1Y/N/P47jmnkENm7YL3oqsmI6AK+V6AD99uWDnIw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <script>
        var $ = function(id){return document.getElementById(id)};
        MathJax = {
          jax: ["input/TeX","output/HTML-CSS"],
          chtml: { displayAlign: 'left'      },
          tex: {
            inlineMath: [['$', '$']],
            displayMath:[['$$', '$$'], ['\\[', '\\]']]
          }
          };
    </script>
        <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
        </script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>      
        <script>hljs.highlightAll();</script>
         <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-PY9DT1RWSW"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-PY9DT1RWSW');
        </script>
</head>

    <body>
    <nav class="navbar">
    <div class="container">
      <div class="navbar-brand">
        <a class="navbar-item"  href="/">
          <h1 class="has-text-weight-bold is-capitalized" >Fabio Vila</h1>
        </a>
        <span class="navbar-burger" data-target="navbarMenuHeroA">
          <span></span>
          <span></span>
          <span></span>
        </span>
      </div>
      <div id="navbarMenuHeroA" class="navbar-menu">
        <div class="navbar-end">
          <a href="/" class="navbar-item">
            Home
          </a>
          <a href="https://vilaboard.com" class="navbar-item">
            Vilaboard
          </a>
        </div>
      </div>
    </div>
  </nav>


<section class="section ">
<div class="columns is-centered">
<div class="column is-9 ">
<div class="content is-fluid">

  <header class="mb-5">
    <h1 class="title is-warning">Usando os serviços OpenAI para criar um ChatBot - Python</h1>
    <h4 class="subtitle has-text-weight-light is-family-sans-serif"></h4>
    
    <h4 class="subtitle has-text-weight-light is-family-sans-serif">Aprenda a fazer um chatbot usando os serviços da OpenAI.</h4>
    
    <hr class="m-1"/>
    <small class="pl-2 has-text-dark-grey" ><span class="icon "><i class="fa fa-user "></i></span>
      
      Fabio
         
    <span class="icon"><i class="fa fa-calendar"></i></span>  
     02 Jan 2023
     <span class="icon"><i class="fa fa-bars"></i></span>
    python
    <span class="icon"><i class="fa fa-tag"></i></span>  
    AI, ChatGPT, e python
    </small>
    <hr class="mt-1 mb-5"/>
    
    <div class="h-400">
        
        <img class="image" src="/assets/imgs/1c1b1ada-54b5-41d8-abc9-4ad746983679.jpeg"/>
        
    </div>
    


  </header>

  <article class="mt-5">
    <p>Em 2023 Taylor Swift foi eleita a personalidade do ano, mas há quem diga que 2023 foi mesmo o ano da <strong>Inteligência Artificial</strong>. E de fato há uma corrida das empresas que ficaram para trás do lançamento do modelo  <strong>text-davinci</strong> da OpenAI,era um modelo rudimentar comparado aos <strong>gpt-turbo-3.5</strong> e o <strong>gpt-4</strong> usados hoje, mas fez barulho e mexeu no mercado. Quem se lembra que o lançamento ocorreu quando o mundo ainda estava assutado com a COVID-19 e a Guerra na Ulcrânia, tudo isso acontecia e assustava, mas as atenções e esperanças estavam mesmo para o futuro que já que tinha chegado. O Google lançou o Bard mas não impressionou. A Baidu lançou seu modelo porém restrito ainda a sua área, enquanto a Amazon e a Apple correm atrás do prejuízo. Elon Musk lançou o Grok<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>, mas até o momento tinha fila de espera para usar. A Apple tenta negociar um acordo milionário para poder usar os artigos da imprensa americana para seu modelo de linguagem<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>. A Microsoft foi astuta e financiou a OpenAI quando percebeu o potencial do <strong>GPT-2</strong> e hoje oferece os modernos modelos como serviço pago ou gratuito.</p>

<h3 id="fazendo-um-chatbot-usando-o-openai">Fazendo um chatbot usando o OpenAI</h3>

<p>Fazer um chatbot usando os serviços da OpenAI é simples, usa-se somente UMA chamada de função do módulo da openai em python.</p>
<h4 id="cadastro-e-criação-da-secret-key">Cadastro e criação da Secret Key</h4>
<p>Primeiro é preciso fazer o cadastro na plataforma de serviço OpenAI API no site <a href="https://platform.openai.com/signup">https://platform.openai.com/signup</a>. Até o momento eles oferecem créditos para avaliação do serviço e não é preciso cartão de crédito para usar esses créditos. Entretanto a avaliação fica restrista ao modelo <strong>gpt-3.5-turbo</strong> que não deixa de ser um modelo capaz e poderoso. Se você usa a versão gratuita do site você usa esse modelo.</p>

<p>Feito o cadastro é preciso gerar a OpenAI KEY para que se possa usar os serviços.</p>

<p><img src="/assets/imgs/openaikey.png" alt="Página para criar a Secret Key da OpenAI" /></p>

<p>Clique em “<strong>Create new Secret Key</strong>” para criar sua Secret Key, como visto na figura acima.</p>

<h4 id="instalação-do-módulo-de-acesso">Instalação do módulo de acesso</h4>
<p>Em seguida é necessário instalar o módulo da openai. Isso pode ser feito pelo PIP ou preferencialmente pelo seu gerenciador de pacotes em sua distribuição Linux.</p>
<pre><code class="language-bash">pip install openai</code></pre>

<h4 id="fazendo-sua-primeira-conversa">Fazendo sua primeira conversa</h4>

<p>Finalmente podemos fazer a primeira chamada para a OpenAI. Primeiramente é preciso criar uma instância OpenAI usando sua SECRET_KEY do passo anterior. Para fazer uma requisição usa-se o <strong>chat.completions.create</strong> como visto no código abaixo:</p>

<pre><code class="language-python">
# Importa o módulo OpenAI instalado com pip anteriormente
from openai import OpenAI
# Cria uma instância OpenAI. Utilize aqui sua Secret Key no lugar de SUA_SECRET_KEY ( entre aspas )
client = OpenAI(SUA_SECRET_KEY)

# Finalmente fazemos uma requisição ao serviço de chat
completion = client.chat.completions.create(
model="gpt-3.5-turbo",  # Modelo usado.
# A personalidade e o texto enviado ao chat.
messages=[
    {"role": "system", "content": "Você é um assistente virtual divertido e bem humorado."},
    {"role": "user", "content": "Qual o sentido da vida?"}
]
)

# E finalmente exibimos a resposta do modelo "gpt-3.5-turbo" a questão "Qual o sentido da vida?"
print(completion.choices[0].message)
</code></pre>

<h4 id="personalizando-e-embutindo-informações">Personalizando e embutindo informações</h4>
<p>Basicamente é só isso. Configura a Key e chama os serviço de complementação de texto <strong>completions.create</strong> com a personalidade e a mensagem. Fácil não?!</p>

<p>Agora é uma boa hora para explicar os roles da requisição. Como se pode ver no código temos uma <em>list</em> com duas <em>dict</em> com as chaves “role” e “content”. Essas informações serão enviadas ao modelo para configurá-lo com a personalidade e informações que se deseja.</p>

<h5 id="role-system">Role System</h5>

<p>O role system é o mais forte e determina a personalidade do assistente. Veja alguns exemplos de role system:</p>
<ul>
  <li><em>“Você é uma IA da empresa Octopus S.A.. A Empresa está localizada no endereço X e tem o telefone Y.”</em></li>
  <li><em>“Você é um bot do telegram divertido e bem humorado. Sua personalidade é ácida e irônica”</em></li>
  <li><em>“Você é um assistente virtual no twitch do Gamer Lucão, você adora Minecraft e Playstation 5”</em></li>
</ul>

<p>Esse role é opcional. Não é preciso enviar nada se não quiser.</p>

<h5 id="role-assistant">Role Assistant</h5>

<p>O role assistant é útil para enviar a conversa anterior e informações relevantes. Em geral usa-se formatação de strings no python para embutir informações e o texto anterior. Veja alguns exemplos:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">EXPEDIENTE</span> <span class="o">=</span> <span class="s">"estamos abertos até as 18:00hrs"</span> 
<span class="p">...</span>
<span class="p">{</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"system"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="sa">F</span><span class="s">"Hoje é </span><span class="si">{</span><span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">()</span><span class="si">}</span><span class="s"> e hoje </span><span class="si">{</span><span class="n">EXPEDIENTE</span><span class="si">}</span><span class="s">."</span><span class="p">}</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">REQ_ANT</span> <span class="o">=</span> <span class="s">"Onde compro o Dipirona?"</span>
<span class="n">RESP_ANT</span> <span class="o">=</span> <span class="s">"Olá, Você pode comprar na farmácia ..."</span>
<span class="p">...</span>
<span class="p">{</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"system"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="sa">F</span><span class="s">"Anteriormente o usuário solicitou '</span><span class="si">{</span><span class="n">REQ_ANT</span><span class="si">}</span><span class="s">' e você respondeu '</span><span class="si">{</span><span class="n">RESP_ANT</span><span class="si">}</span><span class="s">'."</span><span class="p">}</span>
</code></pre></div></div>

<h5 id="role-user">Role User</h5>

<p>O role user é onde as mensagens do usuário serão inseridas. No exemplo acima foi a mensagem “Qual o sentido da vida?”.</p>

<h3 id="limitações">Limitações</h3>

<p>Cada requisição é única e não tem memória. Ele não se lembra das requisições anteriores. Para que o modelo saiba o que foi dito anteriormente e ele possa continuar a conversa o histórico deve ser passado no role assistant.
Também há um limite de informações que pode ser colocado nos roles. O conjunto dos roles é chamado <strong>contexto</strong>.  O limite do contexto é dado em tokens e atualmente é 4096 tokens, mas há modelos que tem 16k tokens.</p>

<p>Tokens podem ser uma letra ou uma palavra inteira, depende do vocabulário usado pelo modelo. Não conte as letras para verificar o limite de tokens, pois como dito, os tokens podem ser uma letra ou um pedaço de uma palavra ou uma palavra inteira.</p>

<p>Os modelos tem controle de conversas tóxicas, ilegais, abusivas e temas sensíveis. Não peça para o modelo contar um conto erótico que dificilmente ele o fará. Também não é possível inventar histórias mentirosas de pessoas ou temas sensíveis. O modelo tem personalidade multicultural, feminista e woke.</p>

<p>Quando acabar seus créditos só será possível continuar requisitando com um cartão de crédito onde será cobrado por tokens. Não é muito, você brincando sozinho consumirá menos de \$ 1,00 ou em uso mais intensivo \$ 5,00. Você pode configurar um limite no site para no caso de passar desse valor ele pare de responder as requisições.</p>

<h3 id="empresas">Empresas</h3>

<p>Algumas observações são importantes quando for usar o chatbot em empresas. Vamos imaginar um cenário onde o chatbot deverá ser usado para consultar um grande banco de dados de produtos e como se percebeu a limitação do contexto (os roles system, assistant e user) não tem como colocar todos os produtos e suas caracteristicas no contexto da requisição, isso é impraticável.</p>

<p>Para que uma grande base de dados seja ‘ligada’ ao chatbot deverá ser usado um <em>Langchain</em> ou um <em>Information Extration</em>.
O <em>Langchain</em> usa duas camadas. A primeira etapa é a indexação da base de dados que você quer disponibilizar ao chatbot. Nesta etapa documentos, pdfs, textos, planilhas são indexadas por um <em>modelo de embedded</em> que gerará um grande vetor de números de ponto flutuante. Esse vetor representará uma sentença do texto e será armazenado em um banco de dados vetorial ( Vector Database ).</p>

<p>Quando o usuário fizer uma requisição a requisição irá novamente para esse modelo embedded que gerará um vetor embedded representando a requisição e o banco de dados será consultado com o valor que mais se aproxima do vetor da requisição.
Encontrado a informação, a informação é retornada para o chatbot para ele gerar uma resposta com a informação obtida do banco de dados.</p>

<p><strong>Exemplo:</strong></p>

<p>Um escritório de advocacia quer um chatbot ajudando seus advogados.</p>

<p><strong>Primeira etapa ( pode ser feita somente uma vez ):</strong></p>
<ul>
  <li>Reunir todos os documentos, leis, sentenças e diário oficiais que achar necessário.</li>
  <li>Extrair as sentenças ( por exemplo fazendo um <code class="language-plaintext highlighter-rouge">.split(".")</code> no texto ).</li>
  <li>Gerar um vetor embedded para cada sentença.</li>
  <li>Amazenar os vetores embedded em um banco de dados vetorial.</li>
</ul>

<p><strong>Segunda etapa (a cada requisição ):</strong></p>
<ul>
  <li>O usuário digita uma requisição por exemplo <em>“O Sr. Antonio de oliveira tem algum processo cível?”</em></li>
  <li>O modelo embedded gera um vetor com o texto da requisição.</li>
  <li>O banco de dados é consultado com esse vetor para achar a sentença mais próxima.</li>
  <li>Ele achou por exemplo <em>“Antonio de oliveira x José no nascimento”</em></li>
  <li>A informação é adicionada ao role assistant para o chatbot gerar uma resposta.</li>
</ul>

<p>O Information Extration é diferente este não usa um modelo embedded. Ele extrai a intenção do usuário e as palavras chaves que serão usados para montar diretamente uma requisição SQL ao banco de dados que então retornará a informação a ser inserida nos roles da requisição da resposta.</p>

<p>Langchain e Information Extraction são áreas e ferramentas diferentes mas auxiliares do modelos de linguagem. A OpenAI e outras empresas disponibilizam esses serviços pagos.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p><a href="https://grok.x.ai/">https://grok.x.ai/</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p><a href="https://www.nytimes.com/2023/12/22/technology/apple-ai-news-publishers.html">https://www.nytimes.com/2023/12/22/technology/apple-ai-news-publishers.html</a> <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </article>

</div>
</div>
</div>
</section>

<section class="section">
  <hr/>
  <nav class="level is-mobile">

    <div class="level-item">      
      
      
      <div>
        <p class="heading"><strong>Veja Também:</strong></p>
        <a href="/aplicadas/2022/10/20/cvpy-knapsack.html"><small>Usando CVXPY para o problema da mochila (knapsack) - Otimização</small></br></a>
        <a href="/aplicadas/2023/01/10/problema-dual-primal.html"><small>O problema dual e primal - Otimização Matemática</small></a>
      </div>
    </div>
  </nav>
</section>
<section class="section">
  <div id="disqus_thread"></div>
<script>
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://fabiovila-github-io.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>


<section>
    <footer class="footer is-primary">
    </footer>
</section>

</body>
</html>
