{
    "url" : ["/programa%C3%A7%C3%A3o/2025/01/11/sobre-tohost-fromhost.html","/educa%C3%A7%C3%A3o/2024/12/14/10-exerc%C3%ADcios-probabilidade-banca-quadrix.html","/automa%C3%A7%C3%A3o/2024/11/29/motores-passo-padrao-NEMA-CNC-impressao-3d.html","/aplicadas/2024/10/17/runge-kutta-em-javascript.html","/app/2024/07/17/codigo-falhas-obd2-ecu.html","/app/2024/01/24/calculo-resistores.html","/app/2024/01/23/calculo-capacitores.html","/eletronica/2023/12/29/geradores-e-divisores-de-oitavas-org%C3%A3os-antigos.html","/aplicadas/2023/12/01/criando-seu-proprio-vocabulario-no.html","/eletronica/2023/11/15/siglas-de-sensores-obd2.html","/aplicadas/2023/01/10/problema-dual-primal.html","/python/2023/01/02/usando-servicos-openai.html","/aplicadas/2022/10/20/cvpy-knapsack.html","/educa%C3%A7%C3%A3o/2022/08/02/probabilidade-classica-frequentista-e-subjetiva.html","/aplicadas/2022/08/01/infer%C3%AAncia-estatistica.html","/eletr%C3%B4nica/2021/02/10/simulacao-circuito-RL-python.html","/eletr%C3%B4nica/2021/01/10/filtro-fir.html","/ci%C3%AAncias/2020/06/10/o-t%C3%A9cnico-que-chutou-a-maquina-copy.html"],
    "title" : ["Sobre tohost e fromhost - RISCV","10 Questões de probabilidade resolvidas da Banca Quadrix - Matemática","Padrão NEMA em motores de passo na construção de CNC e Impressoras 3D - Automação","Explorando o método Runge-Kutta em javascript","Significado dos códigos de falha DTC OBD2 da ECU - Aplicativo","Cálculo de resistência pelas cores do resistor - Aplicativo","Código de Cores de capacitores - Aplicativo","Órgãos Antigos dos Anos 70: Geradores e Divisores de Oitavas - Música Eletrônica","Criando seu próprio vocabulário BPE no Tokenizers - Python","Siglas de sensores e atuadores OBD2 - Eletrônica automotiva","O problema dual e primal - Otimização Matemática","Usando os serviços OpenAI para criar um ChatBot - Python","Usando CVXPY para o problema da mochila (knapsack) - Otimização","Probabilidade clássica frequentista e subjetiva - Matemática","Inferência estatística - Matemática","Usando Python para resolver ODEs de circuitos elétricos: RL - Python","Filtros FIR - Processamento de sinais","O técnico que chutou a máquina - Filosofia da Ciência"],
    "content" : "[\"Resumo e Explicação da Funcionalidade de tohost e fromhost no Spike e em Ambientes RISC-V\\n\\nA comunicação entre o simulador Spike e o programa em execução é realizada por meio de dois registradores especiais: tohost e fromhost. Esses registradores não fazem parte de um padrão oficial do RISC-V, mas são uma convenção adotada pela equipe da UC Berkeley para permitir a interação entre o host (sistema que executa o simulador) e o target (código RISC-V em execução no simulador).\\n\\nDefinição e Função\\n\\n\\n  \\n    tohost: Este registrador é utilizado para enviar comandos e dados do target para o host. A escrita de valores específicos em tohost pode disparar a realização de uma chamada de sistema (syscall) ou a terminação do programa em execução.\\n\\n    \\n      Se o bit menos significativo (LSB) for 0, os bits superiores representam um ponteiro para uma estrutura que descreve a chamada de sistema.\\n      Se o LSB for 1, os bits superiores contêm o código de saída do programa, onde o valor 0 indica sucesso e qualquer outro valor indica falha.\\n    \\n  \\n  \\n    fromhost: Este registrador é usado pelo host para enviar respostas ou comandos ao target. O target deve verificar periodicamente o valor de fromhost para identificar novos comandos recebidos.\\n  \\n\\n\\nDefinição de tohost e fromhost\\n\\nPara se comunicar com o simulador uma região da memória precisa ter o simbolo associado a estas duas localidades. Há duas formas de se fazer isso. A primeira é através do linker script:\\n\\nOUTPUT_ARCH(\\\"riscv\\\")\\n\\nENTRY(_start)\\nEXTERN(_vectors)\\nSECTIONS\\n{\\n\\n    . = 0x80000000;\\n\\n    .tohost : ALIGN(0x1000)\\n    {\\n        *(.tohost)\\n    }\\n\\n    .fromhost : ALIGN(0x1000)\\n    {\\n        *(.fromhost)\\n    }\\n\\n    .text : ALIGN(0x1000)  {DEFINIÇÕES DA SEÇÃO .text}\\n}\\n\\nE no código em C associamos uma variável a essas seções:\\n\\nvolatile unsigned long tohost __attribute__((section(\\\".tohost\\\")));\\nvolatile unsigned long fromhost __attribute__((section(\\\".fromhost\\\")));\\n\\nEntão basta escrever/ler nessas variáveis que o simulador estará monitorando.\\n\\nA segunda forma é através de código em assembly:\\n\\n.section .text\\n\\n.globl exit\\n# Função void exit(long) RV64\\n.globl exit\\nexit:\\n        slli a0, a0, 1\\n        ori a0, a0, 1\\n        la t0, tohost\\n        sd a0, 0(t0)\\n        1: j 1b\\n\\n.globl putchar\\nputchar:\\n        li  t1, 0x0101000000000000\\n        or  a0, t1, a0\\n        la  t0, tohost\\n        sd  a0, 0(t0) # Cuidado não é sb!! sb grava bytes.\\n        ret\\n\\n.section .tohost, \\\"aw\\\", @progbits\\n.align 6\\n.globl tohost\\ntohost: .dword 0\\n\\n.align 6\\n.globl fromhost\\nfromhost: .dword 0\\n\\nOnde se ve as definições de fromhost e tohostbem como um exemplo de aplicação definindo a função void exit(long) e void putchar(int).\\n\\nExemplo de Uso\\n\\nSuponha que temos um programa bare-metal que precisa realizar uma chamada de sistema para imprimir um caractere no console. O processo seria semelhante ao seguinte:\\n\\n\\n  O programa escreve um valor especial em tohost, indicando que deseja realizar uma operação de saída de caractere.\\n  O Spike detecta a escrita em tohost e interpreta o comando.\\n  O Spike executa a ação correspondente (por exemplo, imprime o caractere no console).\\n  Se necessário, o Spike pode responder ao programa por meio de fromhost.\\n\\n\\nEstrutura do Registro tohost\\n\\n\\n  Bits 63:56: Indicam o dispositivo. Existem dois dispositivos principais:\\n    \\n      Dispositivo 0: Usado para chamadas de sistema (syscalls).\\n      Dispositivo 1: Dispositivo de caractere bloqueante (para leitura/escrita de caracteres).\\n    \\n  \\n  Bits 55:48: Indicam o comando:\\n    \\n      Comando 0: Leitura de caractere (somente dispositivo 1).\\n      Comando 1: Escrita de caractere (somente dispositivo 1).\\n    \\n  \\n  Bits 47:0: Contêm o payload, que pode ser um ponteiro para uma estrutura de chamada de sistema ou um caractere a ser escrito.\\n\\n\\nConsiderações para RV32\\n\\nEmbora tohost e fromhost tenham um formato de 64 bits, em sistemas RV32 esses registradores são acessados como duas palavras de 32 bits. Isso pode causar problemas de concorrência ao escrever valores de 64 bits em sistemas RV32, pois a escrita ocorre em duas etapas. No entanto, devido ao fato de o Spike processar blocos de instruções (geralmente em lotes de 5000), esse problema raramente se manifesta.\\n\\nExemplo de Implementação no FreeRTOS\\n\\nEm uma demonstração do FreeRTOS executando no Spike, tohost e fromhost são utilizados para permitir que o sistema operacional emule chamadas de sistema Unix-like, possibilitando a saída de informações para o console e a interação com o host.\\n\\nLimitações e Alternativas\\n\\nEmbora tohost e fromhost sejam mecanismos útis, eles apresentam algumas limitações:\\n\\n  A falta de suporte completo para dispositivos em RV32.\\n  O uso de “magic numbers” (valores mágicos) que não são bem documentados.\\n\\n\\nComo alternativa, recomenda-se o uso de chamadas de sistema por proxy (proxy syscalls), que oferecem uma interface mais padronizada e flexível para a comunicação entre o target e o host.\\n\\nConclusão\\n\\nA funcionalidade de tohost e fromhost é essencial para a execução e interação de programas bare-metal e sistemas operacionais no simulador Spike. Embora seja um mecanismo eficiente, a falta de documentação adequada torna seu uso complexo para novos desenvolvedores. Alternativas como proxy syscalls podem ser mais apropriadas em aplicações modernas.\\n\\nReferências\\n\\n  Código-fonte do Spike e exemplos de uso de tohost e fromhost.\\n  Documentação do OpenSBI e do FreeRTOS para RISC-V.\\n  Discussões em repositórios de projetos relacionados ao ecossistema RISC-V.\\n\\n\\n\", \"\\nQuadrix - 2024 - CRQ - 12ª Região (GO, TO e DF) - Agente Fiscal - 2024Bárbara é proprietária de uma coleção de pedras preciosas, composta de 5 rubis e de 5 esmeraldas, sendo cada uma única e distintiva. Recentemente, Bárbara adquiriu um elegante porta‑joias com 10 compartimentos dispostos em fileira para exibir suas preciosidades. Bárbara, então, pretende alocar uma joia em cada espaço.\\nCom base nessa situação hipotética, julgue o item.Se Bárbara decidir alocar suas joias de forma aleatória, a probabilidade de que todos os rubis fiquem juntos é de 1 em 42.\\n\\nCerto\\nErrado\\n\\n\\nSolução\\n\\nFileiras nesta questão refere-se a compartimentos dispostos lado-a-lado em linha reta, dessa forma, se as jóias forem dispostas aleatoriamente a questão afirma a probabilidade igual a $1 \\\\over 42$ dos rubis estarem lado-a-lado, ou seja, juntos.\\n\\nPrimeiramente vamos calcular o número de possibilidades de disposição das jóias nos 10 compartimentos para fins didáticos. Como todas as 10 jóias são utilizadas nos 10 compartimentos e há elemento repetidos esse é um caso de Permutação com elementos repetidos, cuja fórmula é\\n\\n\\\\[P_{n}^{k,j} = {n! \\\\over k!j!}\\\\]\\n\\nSendo n = 10, k = 5 e j = 5, então\\n\\n\\\\[P_{10}^{5,5} = {10! \\\\over 5!5!} = 252\\\\]\\n\\nPara saber o número de possibilidades de se agrupar os 5 rubis em 10 compartimentos podemos pensar nos 5 rubis como uma unidade só como um bloco. Se considerarmos o inicio do bloco fica fácil contar as possibilidades ao colocar o bloco nos compartimentos 1,2,3,4,5 ou 6, logo são no total 6 possibilidades de disposição, logo a probabilidade dos rubis estarem juntos será\\n\\n\\\\[P = {6 \\\\over 252} = {1 \\\\over 42}\\\\]\\n\\nA afirmação está Certa.\\n\\n\\nQuadrix - 2012 - CREFONO-4ª Região - Fiscal - 2012Numa urna estão 100 (cem) bolinhas numeradas de 1 a 100. Retiram-se 2 delas, sem reposição. A probabilidade de que a soma das 2 bolinhas tiradas seja 100 é de:\\n\\nA) 1/200\\nB) 32/4501\\nC) 32/99\\nD) 49/4950\\nE) 49/99\\n\\n\\nSolução\\n\\nQuestão clássica de urnas e bolinhas numeradas. Retirar duas bolinhas sem reposição é um caso de combinação $C(100,2)$,\\n\\n\\\\[C(n,k) = C(100,2) = {n! \\\\over k!(m-k)!}  = {100! \\\\over 2!(100-2)!} = 4950\\\\]\\n\\nDessa forma serão 4950 possibilidades de se retirar 2 bolinhas quaisquer sem qualquer distinção.\\n\\nPrecisamos saber então quais os casos em que dois números até 100 somam 100.\\nA bolinha de numero 100 com outra qualquer somam mais de 100, logo a descartamos.\\nA bolinha 50, se retirada, não terá outra bolinha 50 para somarem 100, logo a descartamos também.\\nTodas as outras bolinhas tem um par que juntas somam 100, logo os números incluidos são [1,49] e [51,99].\\n\\nO primeiro evento terá sucesso se uma bolinha desse intervalo for retirado logo\\n\\n\\\\[P_{1° Evento A} = {98 \\\\over 100}\\\\]\\n\\nO segundo evento terá sucesso novamente se uma bolinha que some 100 com a primeira for retirada logo\\n\\n\\\\[P_{2° Evento B} = {1 \\\\over 99}\\\\]\\n\\nO que é pedido é a probabilidade da intersecção de dois eventos sucessivos cuja fórmula é\\n\\n\\\\[P(A \\\\cap B) = P(B|A) \\\\times P(A) =  P(A|B) \\\\times P(B)\\\\]\\n\\n$P(B|A)$ é a probabilidade de B ocorrer dado que A já ocorreu, isso demonstra que o 1° evento é independente, porém o 2° evento é dependente do 1°. Substituindo os valores temos:\\n\\n\\\\[P(A \\\\cap B) = {1 \\\\over 99} \\\\times {98 \\\\over 100} = {98 \\\\over 9900} = {49 \\\\over 4950}\\\\]\\n\\nAlternativa D.\\n\\n\\nQuadrix - 2023 - CRM - MG - Estatístico - 2023 Gael possui três moedas distintas: a primeira tem duas caras; a segunda tem uma cara e uma coroa; e a terceira tem duas coroas. Uma dessas moedas foi escolhida aleatoriamente e lançada, resultando em cara.\\nCom base nessa situação hipotética, a probabilidade de que o outro lado dessa moeda também seja cara é de\\n\\nA) 1/4\\nB) 1/3\\nC) 1/2\\nD) 2/3\\nE) 3/4\\n\\n\\nSolução\\n\\nPara auxiliar é útil montar a árvore de probabilidade, como são eventos equiprováveis as probabilidades estão expressas em cima de cada evento, veja que o evento valor da face da moeda é posterior a escolha da moeda por isso cada face tem probabilidade ${1 \\\\over 3}\\\\times {1\\\\over2} = {1\\\\over6}$.\\n\\n            1/3         1/6 (1/3 * 1/2)\\n                    -&gt; Cara  \\n    -&gt; Primeira Moeda M1\\n                    -&gt; Cara\\n                    -&gt; Cara  \\n    -&gt; Segunda  Moeda M2\\n                    -&gt; Coroa  \\n                    -&gt; Coroa  \\n    -&gt; Terceira Moeda M3\\n                    -&gt; Coroa  \\n\\n\\nA questão pede $P(M1|\\\\text{”Cara”})$, ou seja, a probabilidade da Primeira Moeda ocorrer dado que um Cara aconteceu. Resolvemos a questão aplicando o Teorema de Bayes\\n\\n\\\\[P(M1|\\\\text{”Cara”}) = {P(\\\\text{”Cara”}|M1)P(M1) \\\\over P(\\\\text{”Cara”})}\\\\]\\n\\nAntes precisamos calcular os valores a priori:\\n\\n$P(M1) = {1 \\\\over 3}$\\n\\n$P(\\\\text{“Cara”})=P(\\\\text{“Cara”}∣M1)P(M1)+P(\\\\text{“Cara”}∣M2)P(M2)+P(\\\\text{“Cara”}∣M3)P(M3) =$\\n\\n$= {1 \\\\over 3} + {1 \\\\over 6} + 0 = {1 \\\\over 2}$\\n\\n\\\\[P(\\\\text{”Cara”}|M1) = 1\\\\]\\n\\nCalculando,\\n\\n\\\\[P(M1|\\\\text{”Cara”}) = { 1 \\\\times {1 \\\\over 3} \\\\over {1 \\\\over 2} } = {2 \\\\over 3}\\\\]\\n\\nAlternativa D.\\n\\n\\nQuadrix - 2022 - CRP - 11ª Região (CE) - Assistente Administrativo  - 2022As irmãs Bianca e Sofia estão jogando um jogo de cartas com um baralho que possui dez cartas, no total. Conforme as regras desse jogo, deve-se tirar três cartas desse baralho, memorizá-las e devolvê-las ao baralho, embaralhando-o. Em seguida, deve-se escolher três novas cartas e anotar o número de cartas que vierem repetidas nesse grupo. Então, embaralha-se novamente o baralho, e a outra irmã repete o mesmo processo. Quem tiver mais cartas repetidas vence o jogo. Se as duas irmãs tirarem o mesmo número de cartas repetidas, o jogo termina empatado.Com base nessa situação hipotética, julgue o item.A chance de se tirar exatamente uma carta repetida é menor que 50%. \\n\\nCerto\\nErrado\\n\\n\\nSolução\\n\\nQuestão que envolve interpretar bem o texto para não se perder. O jogo é feito em 4 rodadas onde as duas primeiras a mesma pessoa retira na primeira rodada 3 cartas, memoriza e devolve as cartas ao baralho e faz outra retirada anotando as cartas repetidas.\\n\\nHá $C(10,3) = 120$ combinações possíveis de se retirar 3 cartas de um baralho com 10 o que dá uma probabilidade de cada jogo de $1 \\\\over 120$, porém a questão não pergunta isso, ela pergunta qual a chance de somente UMA carta seja repetida no segundo jogo.\\n\\nA carta repetida pode ser qualquer uma das 3 primeiras, restando duas não repetidas que tem $C(7,2) = 21$ combinações possíveis e como são 3 cartas para cada dessas 21 combinações obtem-se, então, no total $21 \\\\times 3 = 63$ combinações de jogos com apenas uma carta repetida.\\n\\nLogo a probabilidade é $P = {63 \\\\over 120} = 52,5%$, dessa forma a afirmação está Errada.\\n\\n\\nQuadrix - 2021 - CRESS-PB - Agente Fiscal - 2021Em um grupo de amigos, 10 assistem a jogos de futebol, 6 assistem a jogos de tênis e 7 assistem a jogos de basquete. Há 3 amigos que assistem aos jogos de futebol e de tênis, 5 que assistem aos jogos de futebol e de basquete e 2 que assistem aos jogos de basquete e de tênis. Todos do grupo assistem a jogos de pelo menos 1 desses esportes, mas apenas 1 dos amigos acompanha todos os 3.Com base nesse caso hipotético, julgue o item.Selecionando-se um subgrupo de 3 desses amigos aleatoriamente, a probabilidade de ao menos 1 gostar de tênis é de 11/13 . \\n\\nCerto\\nErrado\\n\\n\\nSolução\\n\\nEssa é uma ótima oportunidade para se aplicar o princípio da inclusão-exclusão para determinar a quantidade dos amigos:\\n\\n$n(A\\\\cup B\\\\cup C) = n(A) + n(B) + n(C) - n(A \\\\cap B) - n(A \\\\cap C) - n(B \\\\cap C) + n(A \\\\cap B \\\\cap C)$\\n\\nSubstituindo,\\n\\n$n(F\\\\cup T\\\\cup B) = 10 + 6 + 7 - 3 - 2 - 5 + 1 = 14$\\n\\nAntes é preciso resolver os conjuntos das preferências utilizando o diagrama de Venn ilustrado na figura abaixo:\\n\\n\\n3221FutebolTênisBasquete4111076\\n\\n\\nDessa forma, no total são 14 amigos. Se 3 amigos são selecionados de 14, então serão $C(14,3) = 364$ combinações diferentes.\\n\\nUma forma rápida de calcular a probabilidade é descobrir a razão dos que não assistem tênis e achar então através de $1-P$ a razão desejada, dessa forma\\n\\n\\\\[C(8,3) = 56 \\\\rightarrow P = 1- {56\\\\over364} = {11\\\\over13}\\\\]\\n\\nPortanto a afirmação está Certa.\\n\\n\\nQuadrix - 2022 - Câmara de Goianésia - GO - Auxiliar Administrativo Legislativo - 2022Sendo A e B eventos independentes, se P(A) = 0,4  e  P(B) = 0,3, então  P( A ∪ B ) é igual a\\n\\nA) 0,46\\nB) 0,52\\nC) 0,58\\nD) 0,64\\nE) 0,70\\n\\n\\nSolução\\n\\nA união de eventos independentes é calculado pela fórmula:\\n\\n\\\\[P(A\\\\cup B) = P(A) + P(B) - P(A)P(B)\\\\]\\n\\nO enunciado diz que os eventos são independentes, basta então aplicar a fórmula e obter o valor:\\n\\n\\\\[P(A\\\\cup B) = 0,4 + 0,3 - 0,4\\\\times 0,3 = 0,58\\\\]\\n\\nAlternativa C.\\n\\n\\nQuadrix - 2023 - CAU-TO - Agente de FiscalizaçãoAnderson adotou quatro tartarugas e as batizou de Leonardo, Donatello, Michelangelo e Raphael. Para diferenciá-las, ele decidiu colocar uma faixa colorida em cada uma delas: uma faixa azul em Leonardo; uma faixa roxa em Donatello; uma faixa laranja em Michelangelo; e uma faixa vermelha em Raphael. No entanto, no dia seguinte, as faixas haviam caído e Anderson não conseguia determinar qual tartaruga correspondia a cada faixa. Ele resolveu, então, colocar as faixas novamente, mas agora não tem certeza de as ter colocado nas tartarugas corretas.\\nCom base nessa situação hipotética, julgue o item.A probabilidade de Anderson ter acertado a faixa de apenas uma tartaruga é de 1/3 . \\n\\nCerto\\nErrado\\n\\n\\nSolução\\n\\nComo todos as faixas são usadas e a ordem importa o conjunto universo das atribuições das faixas é obtido calculando as Permutações cuja fórmula é somente o Fatorial da quantidade de elementos, ou seja, 4 faixas.\\n\\n\\\\[n(U) = 4! = 24\\\\]\\n\\nentão a probabilidade de acertar todas as faixas é de $P = {1 \\\\over 24}$, porém a questão pede a probabilidade de acertar apenas uma faixa, neste caso fixando-se uma faixa correta há 4 casos como este. Essa é uma boa hora para introduzir a Permutação Caótica ou Desarranjo; método para calcular o número de permutações em que os elementos estão fora da posição original. Fixando 1 faixa é necessário saber quantas combinações não tem nenhum faixa correta.\\nA fórmula do desarranjo é dada por:\\n\\n\\\\[!n = n! \\\\sum {(-1)^k \\\\over k!}, \\\\text{onde k = 0 até n}\\\\]\\n\\nComo uma fita foi fixada, o desarranjo é calculado para as 3 fitas restantes, assim\\n\\n\\\\[!3 = 3! ( 1 - {1 \\\\over 1!} + {1 \\\\over 2!} - {1 \\\\over 3!}) = 2\\\\]\\n\\nNa prática alterna-se os sinais das frações com um fatorial incremental no denominador.\\n\\nOutra forma é fazer manualmente a contagem\\n\\n\\n  A B C D ( Todas corretas )\\n  A B D C\\n  A C B D\\n  A C D B (1 Correta)\\n  A D B C (1 Correta)\\n  A D C B\\n\\n\\nLogo são 2 casos de sucesso para cada fita, consequentemente serão $4 \\\\times 2 = 8$ união de eventos, o que resulta em\\n\\n\\\\[P(\\\\text{’1 fita certa’}) = {8 \\\\over 24} = {1 \\\\over 3}\\\\]\\n\\nPortanto a afirmação da questão está Certa.\\n\\n\\nQuadrix - 2022 - SEDF - Professor de Educação Básica - Matemática - Edital nº 31Vinícius afirmou que leva de 15 a 20 minutos para sair de sua casa e chegar à casa de Pedro, seu amigo, andando em linha reta a uma velocidade de 1 m/s. Isso fez Pedro refletir sobre a área em que a casa de Vinícius pode estar localizada. \\nCom base nessa situação hipotética, julgue o item.Considerando-se que a probabilidade de Vinícius morar em qualquer ponto dessa área seja idêntica, então a probabilidade de ele morar a exatamente 15 minutos da casa de Pedro é igual a 3/5 da probabilidade de ele morar a exatamente 20 minutos da casa deste amigo, caso faça o percurso andando. \\n\\nCerto\\nErrado\\n\\n\\nSolução\\n\\nQuestão com um texto que pode confundir na primeira leitura.\\nVinícius vai em linha reta a 1m/s a casa de Pedro. Vinícius então está entre\\n\\n\\\\[1_{m \\\\over s} \\\\times 15_{M} \\\\times 60_{s} = 900_{m}\\\\]\\n\\nE\\n\\n\\\\[1_{m \\\\over s} \\\\times 20_{M} \\\\times 60_{s} = 1200_{m}\\\\]\\n\\nou seja, a casa de Vinícius está contida em uma linha com $1200 - 900 = 300$ metros de comprimento a partir de 900m da casa de Pedro.\\n\\nA questão informa que “Considerando-se que a probabilidade de Vinícius morar em qualquer ponto dessa área seja idêntica” então a probabilidade da casa de Vinícius estar em qualquer ponto desses 300 metros é de ${1 \\\\over 300}$.\\n\\nA afirmação ”então a probabilidade de ele morar a exatamente 15 minutos da casa de Pedro é igual a 3/5 da probabilidade de ele morar a exatamente 20 minutos da casa deste amigo…” está incorreta, porque a probabilidade de ele morar a exatamente 15 minutos é igual probabilidade dele morar exatamente a 20 minutos como dito acima.\\n\\nPortanto a afirmação está Errada.\\n\\n\\nQuadrix - 2022 - SEDF - Professor de Educação Básica - Matemática - Edital nº 31Chama-se sequência de Narayana a sequência infinita dada pela seguinte fórmula de recorrência: $G_1 = G_2 = G_3 = 1, G_4 = 2 \\\\text{ e } G_n = G_{n-1} + G_{n-3}, \\\\forall n \\\\in \\\\mathbb{N} \\\\text{ e } n \\\\geqslant 5$ Com base nessas informações, julgue o item.Selecionando-se um dos dez termos iniciais da sequência de Narayana ao acaso, a probabilidade de ele ser par é de 30%.\\n\\nCerto\\nErrado\\n\\n\\nSolução\\n\\nQuestões para professores costumam cobrar entendimento da notação matemática e leitura.\\n\\nSeguindo a notação da sequência, os 10 primeiros valores da sequência dada serão:\\n\\n\\\\[N_{10} = (1,1,1,2,2+1=3,3+1=4,4+2=6,6+3=9,9+4=13,13+6=19)\\\\]\\n\\n\\\\[N_{10} = (1,1,1,2,3,4,6,9,13,19)\\\\]\\n\\nComo se observa há 3 números pares $(2,4,6)$, logo a probabilidade de selecionar um número par da sequência será igual a $P(Par) = 3\\\\times{1 \\\\over 10} = 30\\\\%$\\n\\nPortanto a afirmação está Certa.\\n\\n\\nQuadrix - 2019 - CRO-GO - Fiscal Regional Em uma pesquisa,  70% dos 200 entrevistados são mulheres. 2/5 das mulheres não sabem cozinhar e 1/3 dos homens é casado.  \\nCom base nessa situação hipotética, julgue o item.Se, entre os entrevistados, há 24 homens que sabem cozinhar, então mais de 51% dos entrevistados sabe cozinhar.\\n\\nCerto\\nErrado\\n\\n\\nSolução\\n\\nPreenchendo a tabela para treinar e auxiliar na resolução:\\n\\n\\n  \\n    \\n      Mulheres\\n      Homens\\n    \\n    \\n      $200 \\\\times {7 \\\\over 10} = 140$140\\n      $200-140 = 60$60\\n    \\n  \\n\\n\\n\\n  \\n    \\n      Mulheres sabem cozinhar\\n      Homens sabem cozinhar\\n    \\n    \\n      $140 - (140 \\\\times {2 \\\\over 5}) = 84$84\\n      24\\n    \\n  \\n\\n\\n\\n  \\n    \\n      Mulheres casadas\\n      Homens casados\\n    \\n    \\n      ?\\n      $60 \\\\times {1 \\\\over 3} = 20$20\\n    \\n  \\n\\n\\nDessa forma $24 + 84 = 108$ pessoas sabem cozinhar; calculando a porcentagem\\n\\n\\\\[{200 \\\\over 108} - {100\\\\% \\\\over x\\\\%}\\\\]\\n\\nobtem-se 54% das pessoas na entrevista sabem cozinhar, portanto a afirmação está Certa.\\n\", \"Entendendo os Padrões NEMA para Motores Elétricos\\n\\nOs padrões da NEMA (National Electrical Manufacturers Association) são fundamentais para especificar e avaliar motores elétricos em diversas aplicações industriais e comerciais. Este artigo apresenta um resumo desses padrões e como eles ajudam na escolha e utilização de motores elétricos.\\n\\nCategorias de Motores Segundo os Padrões NEMA\\n\\nOs motores NEMA são classificados em quatro classes principais, cada uma com características específicas de torque, corrente de partida e deslizamento:\\n\\n\\n  Classe A: Máximo de 5% de deslizamento, corrente de partida alta ou média, torque normal. Usados em ventiladores e bombas.\\n  Classe B: Similar à Classe A, mas com corrente de partida baixa. Comum em sistemas de HVAC.\\n  Classe C: Máximo de 5% de deslizamento, corrente de partida baixa e torque de rotor bloqueado elevado. Ideal para transportadores e bombas de deslocamento positivo.\\n  Classe D: Deslizamento de 5 a 13%, corrente de partida baixa, torque de rotor bloqueado muito alto. Usados em guindastes e sistemas de alta inércia.\\n\\n\\nAlém disso, há os motores Above-NEMA (ANEMA), que não seguem classificações padrão e são projetados para aplicações específicas.\\n\\nEstruturas e Dimensões dos Motores NEMA\\n\\nOs motores são especificados por tamanhos de estrutura (frames), que definem dimensões como altura do eixo, diâmetro, e padrões de montagem. Esses tamanhos são identificados por números e sufixos, como:\\n\\n\\n  T: Dimensões padronizadas.\\n  C: Montagem frontal com flange.\\n  JM/JP: Usados em bombas acopladas.\\n  TEFC (Totally Enclosed Fan Cooled): Enclausurados com ventilação externa para ambientes contaminados.\\n\\n\\nTipos de Carcaças e Proteções\\n\\nOs motores são protegidos contra contaminantes e condições ambientais por diferentes tipos de carcaça:\\n\\n\\n  ODP (Open Drip Proof): Para ambientes limpos e internos.\\n  WPI/WPII (Weather Protected): Protegidos contra partículas grandes e água.\\n  TEFC/TENV: Totalmente fechados para ambientes severos.\\n  XPRF (Explosion-Proof): Resistentes a explosões internas.\\n\\n\\nClasses de Isolamento Térmico\\n\\nOs padrões NEMA também classificam o isolamento térmico, que determina a capacidade de suportar calor:\\n\\n\\n  Classe A: Até 105°C.\\n  Classe B: Até 130°C.\\n  Classe F: Até 155°C.\\n  Classe H: Até 180°C.\\n\\n\\nA escolha da classe depende da temperatura ambiente e das condições de operação.\\n\\nImportância dos Padrões NEMA\\n\\nOs padrões NEMA garantem que motores de diferentes fabricantes sejam intercambiáveis, com dimensões e especificações padronizadas. Isso facilita a manutenção, reposição e adaptação em projetos industriais.\\n\\nAlém disso, o uso correto desses padrões ajuda a melhorar a eficiência energética e a confiabilidade dos sistemas motorizados.\\n\\nUso em Impressão 3D e CNC\\n\\nAssim como outros motores, os motores de passo utilizados em CNC e impressoras 3D seguem os tamanhos de estrutura definidos pelos padrões NEMA. Entre os tamanhos mais comuns para aplicações em CNCs e impressoras 3D destacamos:\\n\\n\\n  NEMA 17: Muito usado em impressoras 3D e pequenas máquinas CNC. Oferece um equilíbrio entre torque e tamanho compacto.\\n  NEMA 23: Mais potente que o NEMA 17, frequentemente usado em máquinas CNC de médio porte e cortadores a laser.\\n  NEMA 34: Usado em máquinas CNC maiores ou em aplicações que exigem alto torque.\\n\\n\\nEsses tamanhos determinam as dimensões físicas e os padrões de montagem, facilitando a integração com os sistemas mecânicos. Dessa forma ao escolher um motor de passo para esses dispositivos, é importante considerar os seguintes fatores:\\n\\n\\n  \\n    Torque: Essencial para mover e manter o posicionamento de cargas mecânicas, como mesas de trabalho ou eixos de impressão. O torque do motor deve ser suficiente para superar a resistência mecânica e manter a precisão.\\n  \\n  \\n    Resolução: Medida em passos por rotação. Motores de passo típicos têm 200 passos por rotação (1,8° por passo), mas podem alcançar resoluções maiores com drivers que suportam microstepping.\\n  \\n  \\n    Drivers de Motor: Os drivers controlam os pulsos enviados ao motor. Para CNCs e impressoras 3D, drivers com suporte a microstepping (como A4988 ou TMC2209) ajudam a suavizar os movimentos e reduzir vibrações.\\n  \\n  \\n    Corrente e Tensão: Determinam a potência do motor. Certifique-se de que a fonte de alimentação e o driver sejam compatíveis com os requisitos do motor.\\n  \\n  \\n    Backlash e Precisão: Embora os motores de passo sejam precisos, o backlash em sistemas mecânicos, como fusos e correias, pode afetar a exatidão. O design mecânico deve minimizar esse efeito.\\n  \\n\\n\\nBenefícios dos Motores de Passo em CNCs e Impressoras 3D\\n\\n\\n  Controle Preciso: Ideal para operações que exigem movimentos finos e repetitivos, como cortes detalhados em CNCs ou camadas de impressão em 3D.\\n  Custo Acessível: Comparados a servomotores, os motores de passo são mais baratos e suficientes para a maioria das aplicações.\\n  Fácil Integração: Interfaces padrão, como as controladoras GRBL e Marlin, simplificam a integração com drivers e software de controle.\\n\\n\\nLimitações dos Motores de Passo\\n\\nApesar das vantagens, é importante considerar as limitações:\\n\\n\\n  Perda de Passos: Em condições de carga excessiva, o motor pode perder passos, prejudicando a precisão.\\n  Baixa Eficiência em Alta Velocidade: O torque diminui à medida que a velocidade aumenta.\\n  Ruído e Vibração: Especialmente em modos de passo inteiro. Drivers avançados ajudam a mitigar esse problema.\\n\\n\\nDicas para Escolha e Configuração\\n\\nÉ importante calcular o torque necessário considerando o peso da carga e a resistência do sistema para não sobrecarregar os drivers e o motor. Drivers como TMC2209 são ideais para impressoras 3D devido ao funcionamento silencioso, enquanto DRV8825 ou DM542 são comuns em CNCs. Utilizar microstepping melhora a suavidade dos movimentos e a resolução. Também é importante levar em conta a temperatura de trabalho dos drivers e motores necessitando da instalação de dissipadores de calor ou ventoinhas nos drivers e motores.\\n\\nConclusão\\n\\nOs motores de passo, especialmente os padronizados pela NEMA, são a escolha ideal para aplicações como CNCs e impressoras 3D devido ao seu equilíbrio entre custo, precisão e confiabilidade. Escolher o modelo certo e configurá-lo corretamente é crucial para o sucesso de qualquer projeto.\\n\", \"Bricando com equações diferenciais pelo método RK4\\n\\nEquações diferenciais frequentemente surgem em modelos que estão associados a sistemas fisicos que armazenam energia, como por exemplo modelos matemáticos com molas, capacitores, pneumáticos, etc…. Entretanto encontrar a solução de uma equação diferencial não é trivial e muitas delas ainda não tem solução algébrica conhecida e por isso esses modelos matemáticos são um campo ativo de estudos. Todavia, não ter uma solução algébrica não impede de se obter seus valores, para tanto, métodos iterativos foram desenvolvidos com este fim.\\n\\nAntes de ver alguns desses métodos em Java Script, abaixo você poderá explorar graficamente equações diferenciais resolvidas pelo método Runge-Kutta implementado aqui.\\n\\nUtilize o formato javascript. O namespace Math pode ser suprimido.\\n\\n\\n\\n  \\n    Parametros\\n  \\n  \\n    \\n      \\n        \\n        Passo para cada iteração (H)\\n      \\n    \\n    \\n      \\n        \\n        Tempo limite\\n      \\n    \\n        \\n      \\n        \\n        Valor inicial de x0\\n      \\n    \\n        \\n      \\n        \\n        Valor inicial de y0\\n      \\n    \\n  \\n\\n\\n\\n  \\n    \\n  \\n  \\n    Calcular\\n  \\n\\n\\n\\n\\nMétodo de Euler\\n\\nO primeiro método iterativo para solução de equações diferenciais foi criado pelo famoso matemático Euler; conhecido justamente como Método de Euler. Esse método faz apenas uma estimativa pontual do próximo valor e continua o processo a partir do último estimado. Como sua estimativa é fraca, erros se acumulam a cada iteração tornando inútil os valores por explodirem ou oscilarem. Entretanto por ser simples e fácil de implementar o método de Euler costuma ser exemplo de partida para estudos desses algoritmos.\\n\\nComo toda equação diferencial que modela um sistema fisico esses métodos partem de uma condição inicial definida pelo usuário e a cada iteração uma estimativa do próximo valor é calculado repetindo-se o processo com o valor anterior.\\n\\nComo este site é primariamente de eletrônica, vamos partir do exemplo do circuito RL abaixo que foi tema de artigo 1 para começar a explorar alguns métodos:\\n\\n\\n\\nPara uma fonte DC de 5V o circuito é modelado pela seguinte equação diferencial\\n\\n$5 = 4700 i{\\\\left(t \\\\right)} + 0.0001 \\\\frac{d}{d t} i{\\\\left(t \\\\right)}$\\n\\nIsolando $di(t) \\\\over {dt}$ obtemos\\n\\n${di(t) \\\\over dt} = \\\\frac{5 - 4700 * i(t)}{0.0001}$\\n\\nO método de Euler é um método simples e didático. Primeiramente precisamos definir a função com a equaçao diferencial que será chamada a cada iteração para se obter o próximo valor. A função didt(t,i) definida abaixo é a equação do circuito RL visto acima.\\nAs condições iniciais são passadas pelos parametros y0 e x0. h é o passo que será dado a cada iteração, pense nisso como uma quantidade do tempo incrementado, e isso é importante, porque em um sistema rápido, digamos o circuito RL com indutância pequena, os valores acontecem rapidamente, enquanto em um modelo muito lento, como por exemplo modelos metereológicos, o tempo é da ordem de horas.\\n\\nfunction didt(t, i) {\\nreturn (5 - 4700 * i) / 0.0001;\\n}\\n\\nfunction Euler(y0, x0, h, final, f) {\\nconst r = [];\\nlet x = x0;\\nlet y = y0;\\n\\nr[0] = y;\\nwhile (x &lt; final) {\\n    y = y + h * f(x, y);\\n    x = x + h;\\n    r.push(y);\\n}\\nreturn r;\\n}\\n\\nr = Euler(0, 0, 0.0001, 0.1, didt);\\n\\nconsole.log(r);\\n\\n\\nAs condições iniciais do circuito no primeiro instante (t = 0) a corrente é igual a 0, logo y0 = 0 e x0 = 0. Como o algoritmo é iterativo cada passo representa uma quantidade no tempo, dessa forma h é a quantidade do passo dado no tempo. Como um circuito como esse se estabiliza rapidamente, h deverá ser da ordem dos micro segundos ou nano segundos. O parametro final informa ao algoritmo quando terminar.\\nO método de Euler é puramente didático. Ele faz péssimas estimativas do próximo valor que vão se acumulando, retornando, então, valores irreais e oscilatórios. De fato no programa acima em poucas iterações os valores se tornam irreais e explosivos.\\n\\nMétodo de Runge-Kutta\\n\\nAmplamente utilizado, o método de Runge-Kutta converge adequadamente, não acumula muitos erros e tem poucas chances de oscilar. Em contraste ao método de Euler as estimativas são feitas através de média aritmética ponderada de 4 valores (K_n).\\n\\nfunction didt(t, i) {\\nreturn (5 - 4700 * i) / 0.0001;\\n}\\n\\nfunction RK(y0, x0, h, final, f) {\\nconst r = [];\\nlet x = x0;\\nlet y = y0;\\nlet k1, k2, k3, k4;\\n\\nr.push(y);\\nwhile (x &lt; final) {\\n    k1 = h * f(x, y);\\n    h2 = h / 2; // Uma pequena otimização\\n    k2 = h * f(x + h2, y + h2 * k1);\\n    k3 = h * f(x + h2, y + h2 * k2);\\n    k4 = h * f(x + h, y + h * k1);\\n    y = y + (h * (k1 + 2 * k2 + 2 * k3 + k4)) / 6;\\n    x = x + h;\\n\\n    r.push(y);\\n}\\nreturn r;\\n}\\n\\nr = RK(0, 0, 0.0001, 0.1, didt);\\n\\nconsole.log(r);\\n\\n\\nCertamente o array pode ser descartado e os valores usados dinamicamente para plotar um gráfico ou apenas o valor final seja de interesse.\\n\\n\\n\\n\\n\\n\\n  \\n    \\n      Usando Python para resolver ODEs de circuitos elétricos: RL - Python &#8617;\\n    \\n  \\n\\n\", \"\\n\\n\\n\\nDigite o código ou alguma palavra para filtrar\\n\\n\\n\\n  \\n  \\n    \\n  \\n  \\n    \\n  \\n\\n\\n\\n\\n  \\n    Procurar\\n  \\n\\n\\n\\n\\n\\n \\n\\n\\n\\nOs comentários, soluções e descrições são genéricos. Cada carro e defeito tem particularidades que as soluções descritas podem não resolver ou ainda piorar o problema. Algumas atividades de manutenção requerem conhecimento técnico prévio, ferramentas adequadas e experiência do operador. Se não sabe o que está fazendo consulte um profissional.\\n\\n\", \"\\n\\n\\n\\n\\n\\n  \\n      1° Faixa\\n      \\n\\n      Preto\\n        \\n        \\n      \\n\\n      Marrom\\n        \\n        \\n      \\n\\n      Vermelho\\n        \\n        \\n      \\n\\n      Laranja\\n        \\n        \\n      \\n\\n      Amarelo\\n        \\n        \\n      \\n\\n      Verde\\n        \\n        \\n            \\n\\n      Azul\\n        \\n        \\n      \\n\\n      Violeta\\n        \\n        \\n      \\n\\n      Cinza\\n        \\n        \\n      \\n\\n      Branco\\n        \\n        \\n      \\n\\n      \\n  \\n\\n    \\n    2° Faixa\\n    \\n      \\n      Preto\\n        \\n        \\n      \\n\\n      Marrom\\n        \\n        \\n      \\n\\n      Vermelho\\n        \\n        \\n      \\n\\n      Laranja\\n        \\n        \\n      \\n\\n      Amarelo\\n        \\n        \\n      \\n\\n      Verde\\n        \\n        \\n            \\n\\n      Azul\\n        \\n        \\n      \\n\\n      Violeta\\n        \\n        \\n      \\n\\n      Cinza\\n        \\n        \\n      \\n\\n      Branco\\n        \\n        \\n      \\n\\n    \\n  \\n\\n    \\n      3° Faixa\\n    \\n    \\n      Preto\\n        \\n        \\n      \\n\\n      Marrom\\n        \\n        \\n      \\n\\n      Vermelho\\n        \\n        \\n      \\n\\n      Laranja\\n        \\n        \\n      \\n\\n      Amarelo\\n        \\n        \\n      \\n\\n      Verde\\n        \\n        \\n            \\n\\n      Azul\\n        \\n        \\n      \\n\\n      Violeta\\n        \\n        \\n      \\n\\n      Cinza\\n        \\n        \\n      \\n\\n      Branco\\n        \\n        \\n      \\n\\n      Ouro\\n        \\n        \\n      \\n\\n      Prata\\n        \\n        \\n      \\n    \\n  \\n\\n    \\n      4° Faixa\\n        \\n      Preto\\n        \\n        \\n      \\n\\n      Marrom\\n        \\n        \\n      \\n\\n      Vermelho\\n        \\n        \\n      \\n\\n      Laranja\\n        \\n        \\n      \\n\\n      Amarelo\\n        \\n        \\n      \\n\\n      Verde\\n        \\n        \\n            \\n\\n      Azul\\n        \\n        \\n      \\n\\n      Violeta\\n        \\n        \\n      \\n\\n      Cinza\\n        \\n        \\n      \\n\\n      Branco\\n        \\n        \\n      \\n\\n      Ouro\\n        \\n        \\n      \\n\\n      Prata\\n        \\n        \\n      \\n    \\n  \\n\\n\\n\\n\\n\\nSelecione as cores acima para obter o resultado\\n\\n  \\n    Valor\\n    Tolerância\\n  \\n  \\n    \\n    \\n  \\n \\n\\n\\nValores comuns de resistores\\n\\n\\n  330Ω é um valor comum para alimentar um LED em 5V com corrente de 10mA\\n  1kΩ é um valor comum para alimentar um LED em 5V com corrente de aproximadamente 3mA\\n    \\n      Esse valor é usado pelo Arduino em série com os LEDs\\n    \\n  \\n  1k2Ω é um valor comum para alimentar um LED em 12V com corrente de aproximadamente 3mA\\n  10KΩ é um valor comum para Pull Up e Pull Down\\n    \\n      Esse valor é usado pelo Arduino como Pull Up\\n    \\n  \\n  510Ω é usado pela placa BluePill (STM32 a 3,3 Volts) como resistor de LEDs\\n  0.18Ω e 0.01Ω são valores comuns para resistores Shunt ( sensores de corrente )\\n  1MΩ é normalmente usado em paralelo com cristais de clock\\n\\n\\nValores Comerciais\\n\\nO comércio não comercializa todos os valores possíveis. A indústria padronizou alguns valores que são multiplicados pela 3° Faixa, por exemplo, o valor 8.2 pode ser 8.2Ω, 82Ω, 820Ω, 8,2KΩ e assim por diante. Na tabela abaixo pode-se conferir esses valores.\\n\\n\\n  \\n    \\n      Padrão\\n      E6, E12 e E24\\n       \\n       \\n    \\n  \\n  \\n    \\n      1.0\\n      1.1\\n      1.2\\n      1.3\\n    \\n    \\n      1.5\\n      1.6\\n      1.8\\n      2.0\\n    \\n    \\n      2.2\\n      2.4\\n      2.7\\n      3.0\\n    \\n    \\n      3.3\\n      3.6\\n      3.9\\n      4.3\\n    \\n    \\n      6.8\\n      7.5\\n      8.2\\n      9.1\\n    \\n  \\n\\n\\nEsses valores são para resistores de tolerância entre 5% e 20%. Para tolerâncias menores entre 1% e 0.1% a quantidade de valores comerciais é maior e neste caso uma faixa adicional é usada para indicar a maior precisão de valores.\\n\\n\\n\\n\", \"\\n\\n\\n\\n\\n\\n  \\n      1° Faixa\\n      \\n\\n      Preto\\n        \\n        \\n      \\n\\n      Marrom\\n        \\n        \\n      \\n\\n      Vermelho\\n        \\n        \\n      \\n\\n      Laranja\\n        \\n        \\n      \\n\\n      Amarelo\\n        \\n        \\n      \\n\\n      Verde\\n        \\n        \\n            \\n\\n      Azul\\n        \\n        \\n      \\n\\n      Violeta\\n        \\n        \\n      \\n\\n      Cinza\\n        \\n        \\n      \\n\\n      Branco\\n        \\n        \\n      \\n\\n      \\n  \\n\\n    \\n    2° Faixa\\n    \\n      \\n      Preto\\n        \\n        \\n      \\n\\n      Marrom\\n        \\n        \\n      \\n\\n      Vermelho\\n        \\n        \\n      \\n\\n      Laranja\\n        \\n        \\n      \\n\\n      Amarelo\\n        \\n        \\n      \\n\\n      Verde\\n        \\n        \\n            \\n\\n      Azul\\n        \\n        \\n      \\n\\n      Violeta\\n        \\n        \\n      \\n\\n      Cinza\\n        \\n        \\n      \\n\\n      Branco\\n        \\n        \\n      \\n\\n    \\n  \\n\\n    \\n      3° Faixa\\n    \\n    \\n      Preto\\n        \\n        \\n      \\n\\n      Marrom\\n        \\n        \\n      \\n\\n      Vermelho\\n        \\n        \\n      \\n\\n      Laranja\\n        \\n        \\n      \\n\\n      Amarelo\\n        \\n        \\n      \\n\\n      Verde\\n        \\n        \\n            \\n\\n      Azul\\n        \\n        \\n      \\n\\n      Violeta\\n        \\n        \\n      \\n\\n      Cinza\\n        \\n        \\n      \\n\\n      Branco\\n        \\n        \\n      \\n\\n      Ouro\\n        \\n        \\n      \\n\\n      Prata\\n        \\n        \\n      \\n    \\n  \\n\\n    \\n      4° Faixa\\n        \\n      Preto\\n        \\n        \\n      \\n\\n      Marrom\\n        \\n        \\n      \\n\\n      Vermelho\\n        \\n        \\n      \\n\\n      Laranja\\n        \\n        \\n      \\n\\n      Amarelo\\n        \\n        \\n      \\n\\n      Verde\\n        \\n        \\n            \\n\\n      Azul\\n        \\n        \\n      \\n\\n      Violeta\\n        \\n        \\n      \\n\\n      Cinza\\n        \\n        \\n      \\n\\n      Branco\\n        \\n        \\n      \\n\\n      Ouro\\n        \\n        \\n      \\n\\n      Prata\\n        \\n        \\n      \\n    \\n  \\n\\n\\n\\n\\n\\nSelecione as cores acima para obter o resultado\\n  \\n  \\n    Valor\\n    Tolerância\\n    Equivalente Atual\\n  \\n  \\n    \\n    \\n    \\n  \\n \\n\\n\\nSubstituição\\n\\nCapacitores com código de cores são antigos e muito encontrados por quem restaura rádios, órgãos ou amplificadores antigos. Para substituir sugere-se os capacitores de poliéster com a capacitância e tensão indicada. Em alguns casos capacitores de cerâmica podem ser usados como substitutos.\\n\\nO ideal é trocar todos os capacitores de equipamentos como esse. É comum encontrar alguns já estourados, rachados, descascando ou com boa aparência mas internamente já deteriorados pelo tempo.\\n\\n\\n\\n\", \"Órgãos Antigos dos Anos 70: Geradores e Divisores de Oitavas\\n\\nOs anos 70 foram uma época de efervescência musical e inovação tecnológica, e os órgãos eletrônicos desempenharam um papel crucial nesse cenário. Esses instrumentos, muitas vezes utilizados em bandas de rock progressivo, jazz fusion e música eletrônica da época, eram dotados de características sonoras únicas, inicialmente construidos com o objetivo de serem fiéis aos órgãos de tubos, sua sonoridade única e portabilidade logo achou seu lugar próprio na música.\\n\\nGeradores de Oitavas: A Base do Som Único\\n\\nOs geradores de oitavas são circuitos eletrônicos projetados para gerar sinais de áudio em diferentes oitavas. No contexto desses instrumentos, os geradores de oitavas eram responsáveis por criar as frequências fundamentais e suas oitavas superiores e inferiores.\\n\\nOs órgãos antigos, como o lendário Hammond B3, utilizavam geradores de oitavas para produzir um som encorpado e cheio. A manipulação desses geradores nos Drawbars permitia aos músicos criar timbres ricos e expressivos, tornando esses instrumentos essenciais para a música da década.\\n\\nDivisores de Oitavas: Enfatizando a Profundidade Sonora\\n\\nEm adição aos geradores de oitavas, os órgãos antigos dos anos 70 também contavam com divisores de oitavas. Esses dispositivos eram responsáveis por dividir o sinal gerado pelos osciladores em diferentes oitavas, permitindo uma abordagem mais versátil e dinâmica na criação de sons.\\n\\nOs divisores de oitavas eram particularmente notáveis pela forma como enriqueciam a paleta sonora dos músicos. Ao controlar a distribuição do sinal em oitavas específicas, os músicos podiam criar texturas sonoras complexas, empregando escalas e acordes de forma única. Isso proporcionava uma variedade de opções tonais, desde as profundezas ressonantes das oitavas mais baixas até as agudas e cristalinas oitavas superiores.\\n\\nO par de chips S50240 e S10430\\n\\nAntes do advento de circuitos integrados especializados em geração e divisão de oitavas o processo de dividir as frequências das notas eram feitos com flip-flops discretos ou integrados. Os circuitos integrados S50240 e S10430 facilitaram a construção de órgãos eletrônicos polifônicos com o uso de apenas 2 ou três chips especializados.\\nO S50240 é o circuito integrado responsável por sintetizar as oitavas superiores do instrumento. Um oscilador tipicamente de 2Mhz será ligado na entrada e dividido em 12 frequências gerando 12 ondas quadradas com 50% de duty cycle correspondente a cada nota musical.\\nAs divisões podem ser conferidas na tabela abaixo:\\n\\n\\n  \\n    \\n      Divisão\\n      Frequência resultante\\n      Nota\\n    \\n  \\n  \\n    \\n      ÷478\\n      4184.10 Hz\\n      Dó inferior\\n    \\n    \\n      ÷451\\n      4434.60 Hz\\n      Dó sustenido\\n    \\n    \\n      ÷426\\n      4694.80 Hz\\n      Ré\\n    \\n    \\n      ÷402\\n      4975.10 Hz\\n      Ré sustenido\\n    \\n    \\n      ÷379\\n      5277.80 Hz\\n      Mi\\n    \\n    \\n      ÷358\\n      5586.60 Hz\\n      Fá\\n    \\n    \\n      ÷338\\n      5917.20 Hz\\n      Fá sustenido\\n    \\n    \\n      ÷319\\n      6269.60 Hz\\n      Sol\\n    \\n    \\n      ÷301\\n      6644.50 Hz\\n      Sol sustenido\\n    \\n    \\n      ÷284\\n      7042.30 Hz\\n      Lá\\n    \\n    \\n      ÷268\\n      7462.70 Hz\\n      Lá sustenido\\n    \\n    \\n      ÷253\\n      7905.10 Hz\\n      Si\\n    \\n    \\n      ÷239\\n      8362.20 Hz\\n      Dó superior\\n    \\n  \\n\\n\\nO S50240 sozinho nos permite apenas gerar 12 notas fundamentais. Para se obter as notas das oitavas inferiores dois S10430 são usados em conjunto com o S50240. Cada S10430 dividirá 4 notas em 4 oitavas e 2 notas em 3 oitavas totalizando por chip 22 teclas por chip e para se obter 44 teclas dois S10430 são usados em cascata. Cada divisor tem 4 saídas diferentes permitindo que com um potênciometro o músico possa misturar 4 oitavas da mesma nota nos níveis desejados alterando assim o timbre da nota. Além das 4 saídas as entradas das teclas no S10430 são sensíveis a tensão aplicada, permitindo a criação de efeitos de ataques e liberação das teclas, normalmente utilizando circuitos RC em cada tecla.\\n\\nO diagrama abaixo retirado do datasheet do S10430 ilustra facilmente essas ligações.\\n\\n\\n\\nOutros chips\\n\\nEsses chips são obsoletos e difíceis de se achar no mercado, porém não são os únicos a fazerem essa funções. Outras empresas lançaram no mercado outros chips muito conhecidos:\\n\\n13 Note Top Octave Synthetizer (TOS)\\n50% Duty Cycle\\n\\n\\n  MO83B\\n  M50240\\n  M5891B1\\n  S50240\\n  50240\\n\\n\\n\\n\\n13 Note Top Octave Synthesizer (TOS)\\n30% Duty Cycle\\n\\n\\n  MO82B\\n  M50241\\n  M5891A\\n  S50241\\n  50241\\n\\n\\n\\nQual a importância do Duty Cycle?\\nTer um duty cycle de 30% ou 50% influencia nos harmônicos gerados pela onda quadrada. O duty cycle de 50% gera harmônicos impares que para alguns gostos é mais ácido e agudo. Enquanto usar um duty cycle de 30% gera um forte harmônico par resultando em um timbre mais leve e macio. Alguns construtores alegam que um duty cycle de 25% é o melhor valor para gerar harmônicos pares.\\n\\n\\n\\n\\n12 Note Top Octave Synthesizer (TOS)\\n\\n\\n  MO86B\\n  M50242\\n  S50242\\n  50242\\n  AY-1-0212\\n  ECG-2043\\n\\n\\n\\n\\n12 Note Top Octave Synthesizer (TOS)\\n\\n\\n  MO87B\\n  MC86B1\\n  ECG-2043\\n\\n\\nOpções de substituição são poucas. O técnico dependerá de peças velhas. Alguns podem fazer seu próprio TOS utilizando FPGA ou algum microcontrolador rápido o suficiente para gerar 12 ondas quadradas sem desvio de fase. É importante se atentar que a maioria dos órgãos tem Vibrato quando se varia levemente a frequência do oscilador VCO de 2MHz.\\n\\n\\n\\nFontes:\\n\\nhttp://www.armory.com\\n\\nS50240 e S10430 Datasheets\\n\\nWikipedia\\n\", \"Tokenização\\n\\nAo longo da evolução das aplicações NLP várias formas de se representar um texto foram abordadas. Imagine a seguinte frase “Qual o sentido da vida?” como deveríamos representa-lá para ser usada em algum Modelo de Linguagem Natural? Um modelo de linguagem ‘lê’ uma parte do texto e prevê o próximo token, então a primeira abordagem talvez seja óbvia: Atribuir um número a cada letra e usar a sequência de números para representar a frase. Boa notícia, não precisamos atribuir número algum, eles já existem na codificação UTF-8 como vemos abaixo:\\n\\n\\n  \\n    \\n      Qual o sentido da vida?\\n      0x51 0x75 0x61 0x6c 0x20 0x6f 0x20 0x73 0x65 0x6e 0x74 0x69 0x64 0x6f 0x20 0x64 0x61 0x20 0x76 0x69 0x64 0x61 0x3f\\n    \\n  \\n\\n\\nPorém essa representação não funciona muito bem.  Se por exemplo na entrada “Qual o sentido d” nessa codificação por letras sugerida o próximo token poderá ser o “a”, “e” e “o” como nas frases “Qual o sentido de …” e “Qual o sentido do …” e porque não o “i” em “Qual o sentido disso …“, ou seja, a probabilidade do próximo token nessa codificação se diluí dificultando prever o próximo token. A situação piora com o espaço ” “ ou o artigo “a”, praticamente todas as letras/tokens tem a mesma probabilidade de ocorrerem depois deles.\\n\\nOutro problema é o contexto. As redes neurais vão perdendo o contexto ao longo das previsões e uma codificação como essa que precise de muitas iterações para formar uma frase fará a rede perder o ‘tema do assunto’.\\n\\nOutra forma sugerida para resolver esses problemas é atribuir um número as palavras (words) de um vocabulário como no exemplo abaixo:\\n\\n\\n  \\n    \\n      Qual o sentido da vida?\\n      0x13 0x03 0x123 0x10 0x54\\n    \\n    \\n      “Qual “\\n      0x13\\n    \\n    \\n      “o “\\n      0x03\\n    \\n    \\n      “sentido “\\n      0x123\\n    \\n    \\n      “da “\\n      0x10\\n    \\n    \\n      “vida?”\\n      0x54\\n    \\n  \\n\\n\\nNa tabela acima cada palavra+pontuação tem um número associado. São 5 tokens então serão 5 números representando a frase toda. Nessa representação a rede neural faz poucas iterações e não se perde no contexto. De bônus ocupa pouco espaço e consome menos CPU correto? Sim. Mas alguns problemas surgem. Enquanto na representação por letras qualquer palavra do vocabulário pode ser representada, precisaríamos de uma enorme quantidade de números para representar todas as palavras existentes. Normalmente um vocabulário útil desses teria alguns Gigas de tamanho. E o que acontece se alguma palavra não conhecida aparecer? Há quem tenha usado o token &lt;UNK&gt; para representar uma palavra desconhecida … deselegante não?\\n\\nByte-Pair Encoding (BPE)\\n\\nO BPE, usado inicialmente como um algoritmo para comprimir textos, achou seu sucesso nos modelos de linguagens localizando-se no entre-meio da representação por letras e por palavras. Na codificação BPE inicialmente todas as letras são incluídas, em seguida uma pesquisa em uma grande quantidade de textos determinará as palavras e os RADICAIS frequentemente presentes nesses textos que serão incluídos na representação.\\n\\nEm português é extremamente comum o uso das preposições “do”, “da”, “em”; os artigos “um”, “uma”; os advérbios “não”, “sim”, “talvez”, em inglês é imperativo a presença do “the”, “were”, “have”, logo essas palavras são bons candidatos a serem incluídos no vocabulário.\\n\\nAprendemos na escola a formação das palavras utilizando prefixos, sufixos e radicais, partindo disso, os prefixos “íssimo”,”an”, “anti”, “endo”, “hiper” bem como os sufixos “ismo”, “ença”, “ário” e tantos outros são fortes candidatos a serem representados pelo BPE. Por sorte nossa lingua tem radicais muito comuns que também podem ser incluídos na representação.\\n\\nVejamos o exemplo da frase “Qual o sentido da vida?” na codificação BPE usada pelo GPT:\\n\\n\\n  \\n    \\n      Token\\n      Index\\n    \\n  \\n  \\n    \\n      “Qual”\\n      46181\\n    \\n    \\n      ” o”\\n      267\\n    \\n    \\n      ” sent”\\n      1908\\n    \\n    \\n      “ido”\\n      17305\\n    \\n    \\n      ” da”\\n      12379\\n    \\n    \\n      ” v”\\n      410\\n    \\n    \\n      “ida”\\n      3755\\n    \\n    \\n      ”?”\\n      30\\n    \\n  \\n\\n\\nComo se pode ver a palavra “sentido” foi quebrada em dois tokens “ sent” e “ido”, “vida” foi quebrado em “ v” e “ida”; faria mais sentido representar “vida” por “vida”? Sim, mas o vocabulário usado é do GPT-4 e apesar dele ser multilingual ele foi primariamente treinado para o inglês e com poucos textos em português, consequentemente ele tem mais radicais e palavras em inglês que em qualquer outra língua.\\n\\nComo todas a letras estão incluídas qualquer palavra pode ser formada e como os radicais e as palavras mais usadas estão incluídas o contexto fica pequeno. Há um balanço entre flexibilização e tamanho.\\n\\n\\nSe quiser explorar mais a tokenização usada pelo ChatGPT use o site https://observablehq.com/@simonw/gpt-tokenizer exemplificado na imagem abaixo:\\n\\n\\n\\nTreinando seu próprio vocabulário\\n\\nPara treinar seu próprio vocabulário será necessário o módulo python tokenizers. Primeiramente instale o módulo via pip ou usando seu gerenciador de pacotes ( preferido ).\\n\\npip install tokenizers\\n\\n\\nIncluiremos os módulos necessários no cabeçalho do arquivo:\\n\\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, processors\\nimport glob\\n\\n\\nO glob é excelente para essas tarefas ao facilitar adicionar novos arquivos simplesmente jogando eles em um diretório.\\n\\n# Initialize a tokenizer\\ntokenizer = Tokenizer(models.BPE())\\n\\n# Customize pre-tokenization and decoding\\ntokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\\ntokenizer.decoder = decoders.ByteLevel()\\ntokenizer.post_processor = processors.ByteLevel(trim_offsets=True)\\n\\n# And then train\\ntrainer = trainers.BpeTrainer(\\n    vocab_size=32000,\\n    min_frequency=4,\\n    initial_alphabet=pre_tokenizers.ByteLevel.alphabet()\\n)\\n\\n\\nInicializamos o módulo com os parâmetros desejados. Os parâmetros mais importantes são\\n\\n\\n  vocab_size=32000 - Diz qual o tamanho do vocabulário. Muito pequeno ajuda na velocidade da rede mas diminui a quantidade de palavras e radicais. O GPT usa tamanhos de 50k (~50.000) e 100k (~100.000) para seus vocabulários. Não esqueça que as letras serão incluídas, então o tamanho deve contar essas letras obrigatórias.\\n  min_frequency=4 - Frequência minima para um token ser incluído. Se alguém fizer um treinamento com diálogos de internet é muito provável que palavras digitadas erradas apareçam e outras somente uma vez, ou os famigerados kkkkkkkkkk+. É melhor deixar palavras poucos usadas de fora. Porém se o vocab_size for pequeno e a quantidade de textos grande e com muitas palavras é provável que somente palavras com muita frequência sejam incluídas.\\n  initial_alphabet=pre_tokenizers.ByteLevel.alphabet() - Lembra das letras automaticamente incluídas? Não é automático. Elas são incluídas aqui.\\n\\n\\nComo glob será usado …\\n\\nl = glob.glob(\\\"./**/*.txt\\\", recursive=True)\\n\\n\\nQue fará uma lista chamada “l” com todos os aquivos *.txt no diretório e sub-diretório atual.\\n\\nspecials = [\\n    '&lt;|query|&gt;',\\n    '&lt;|answer|&gt;',\\n    '&lt;|endoftext|&gt;',\\n    '&lt;|code|&gt;',\\n    '&lt;|system|&gt;',\\n    '&lt;|hole|&gt;'\\n]\\n\\n\\nEssa etapa é importante. A OpenAI usa muito o token &lt;|endoftext|&gt; para finalizar um texto e começar outro. Também é usado durante a inferência para informar que ela terminou. O token deve ser algo estranho aos textos das linguagens que ele suporta então foi escolhido esse formato estranho &lt;|endoftext|&gt;. Porém essa palavra tem 13 caracteres e ocuparia muito espaço bem como CPU para operá-la. Não seria melhor transformar esse token em um só número como é feito nas palavras e radicais mais usados?\\n\\nPois é isso que é feito nessa fase. Adiciona-se os specials tokens ou tokens especiais que serão usados para alguma finalidade.\\n\\n\\nEu uso o &lt;|query|&gt;, &lt;|endoftext|&gt; e &lt;|answer|&gt; para montar datasets com perguntas e respostas como no exemplo:\\n&lt;|query|&gt;Quem descobriu o Brasil?&lt;|answer|&gt;Pedro Álvares Cabral&lt;|endoftext|&gt;\\nE o três tokens serão convertidos em um só número (cada) do que uma sequência de characteres.\\n\\n\\nConfigurado os parâmetros agora é feito o processo de pesquisa e quando acabar o processo salvamos o *.json do vocabulário gerado para uso posterior.\\n\\ntokenizer.add_special_tokens(specials)\\ntokenizer.train(l, trainer=trainer)\\n\\n# And Save it\\ntokenizer.save(\\\"byte-level-bpe.tokenizer.32k.json\\\", pretty=True)\\n\\n\\nO arquivo byte-level-bpe.tokenizer.32k.json deverá aparecer no diretório atual ao final do processo com o vocabulário gerado.\\n\\nUsando o vocabulário gerado\\n\\nPara carregar o json do vocabulário o Tokenizer tem a função from_file e para codificar um texto qualquer no vocabulário carregado usa-se o tokenizer.encode(texto) que retornará a lista .ids contendo os números dos tokens do texto convertido.\\nO processo inverso, ou seja, transformar uma lista de números obtidos da conversão de tokenizer.encode(texto).ids em texto novamente é feito utilizando decode.\\nLembre-se:\\n\\ntokenizer.encode - Transforma o texto em tokens do vocabulário carregado\\ntokenizer.decode - Transforma uma lista de números em texto dos tokens representados pelo vocabulário carregado.\\n\\n\\nComo se pode ver no exemplo abaixo:\\n\\nimport tokenizers\\nfrom tokenizers import Tokenizer\\nfrom tokenizers.models import BPE\\ntokenizer = Tokenizer.from_file(\\\"byte-level-bpe.tokenizer.32k.json\\\")\\nencode = lambda s: tokenizer.encode(s).ids\\ndecode = lambda l: tokenizer.decode(l)\\n\\nA = encode(\\\"Qual o sentido da vida?\\\")\\nB = decode(A)\\n\\nprint(A,B)\\n\\n\\nPrograma completo\\n\\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, processors\\nimport glob\\n# Initialize a tokenizer\\ntokenizer = Tokenizer(models.BPE())\\n\\n# Customize pre-tokenization and decoding\\ntokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\\ntokenizer.decoder = decoders.ByteLevel()\\ntokenizer.post_processor = processors.ByteLevel(trim_offsets=True)\\n\\n# And then train\\ntrainer = trainers.BpeTrainer(\\n    vocab_size=32000,\\n    min_frequency=4,\\n    initial_alphabet=pre_tokenizers.ByteLevel.alphabet()\\n)\\n\\nl = glob.glob(\\\"./**/*.txt\\\", recursive=True)\\n\\nspecials = [\\n    '&lt;|query|&gt;',\\n    '&lt;|answer|&gt;',\\n    '&lt;|endoftext|&gt;',\\n    '&lt;|code|&gt;',\\n    '&lt;|system|&gt;',\\n    '&lt;|hole|&gt;'\\n]\\n\\ntokenizer.add_special_tokens(specials)\\ntokenizer.train(l, trainer=trainer)\\n\\n# And Save it\\ntokenizer.save(\\\"byte-level-bpe.tokenizer.32k.json\\\", pretty=True)\\n\\n\\n\", \"Se você tem um leitor OBD2 em inglês essa lista pode te ajudar a desvendar as siglas na leitura.\\n\\n\\n  \\n    \\n      Informação exibida\\n      Explicação\\n    \\n  \\n  \\n    \\n      Fuel System 1 Status [Status 1 ou Fuelsys1]\\n      Em sistema de controle OL - Open Loop significa que o controle está sendo feito as ‘cegas’, sem o uso dos sensores. Em modo CL - Closed Loop o controle está sendo feito utilizando os sensores. A sonda lambda é o principal sensor utilizado para controlar a mistura ar-combustível e para funcionar ela precisa estar quente.Ao ligar o carro com o motor frio a sonda lambda (fria) não será utilizada de início, então a ECU operará o motor em modo OL - Open Loop até que a sonda lambda envie os dados corretos quando finalmente a ECU (agora com valores corretos dos sensores já aquecidos) muda para Closed Loop.\\n    \\n    \\n      Calculated Load Value [CLV or Load_PCT]\\n      Carga do motor.\\n    \\n    \\n      Engine Coolant Temp [ECT]\\n      Temperatura do liquido de arrefecimento (água do radiador).\\n    \\n    \\n      Short Term Fuel Trim-Bank 1 [STFT 1 ou SHRTFT1]\\n      Ajuste imediato da mistura estequiometria. Se o valor é positivo a ECU está adicionando combustível (mistura rica) se negativo a ECU está retirando combustível (mistura pobre). Esse ajuste se perde ao desligar o carro. Quando se está ‘descendo na banguela’, por exemplo, com o carro engatado a ECU para de mandar combustível mostrando valores negativos para STFT.\\n    \\n    \\n      Long Term Fuel Trim- Bank 1 [LTFT 1 ou LONGFT1]\\n      Ajuste de longo prazo da mistura com base no histórico do sensor explicado acima. Se por exemplo o sensor imediato ficar por muito tempo em 6% o Long Term Fuel Trim irá incrementar seu ajuste para compensar até que o Short Term fique em 0%. Esse ajuste não se perde ao desligar o carro, é um dos indicadores mais importantes de falhas no motor.\\n    \\n    \\n      Engine RPM [RPM]\\n      O RPM do motor\\n    \\n    \\n      Vehicle Speed Sensor [VSS]\\n      Velocidade do veiculo\\n    \\n    \\n      Ignition Timing Advance #1 [Sparkadv]\\n      Mostra o ângulo de ignição ou mais conhecido como “ponto de ignição”. Diminui com o aumento da temperatura.\\n    \\n    \\n      Intake Air Temp [IAT]\\n      Temperatura do ar.\\n    \\n    \\n      Air Flow Rate from Mass Air Flow Sensor [MAF]\\n      A quantidade de ar entrando no sistema de admissão. Em geral está associado ao sensor MAF.\\n    \\n    \\n      Absolute Throttle Position [TP or ABS_TP]\\n      Posição do sensor de corpo de borboleta. Ao pisar no pedal do acelerador esse sinal deve subir.\\n    \\n    \\n      Bank 1 – Sensor 2 Volts [O2S12]\\n      Tensão da sonda lambda pós catalisador. Em situações normais não deve variar.\\n    \\n    \\n      Bank 1 – Sensor 1 [O2S11]\\n      Tensão da sonda lambda antes do catalisador. No osciloscópio se apresenta como uma onda oscilante entre 900mV e 200mV. Valores acima de 450mV indica mistura rica e valores abaixo mistura pobre. O sinal não deve ser contínuo, mas oscilante. O ideal é oscilar simetricamente em mistura pobre e rica, se ficar por mais tempo acima ou abaixo de 450mV possivelmente é sinal de problemas.\\n    \\n    \\n      OBD Requirements OBD and OBD2 [OBDSUP]\\n      O protocolo de comunicação utilizado pelo OBD\\n    \\n  \\n\\n\", \"Os problemas primal e dual estão intrinsecamente ligados na teoria da dualidade em programação linear. Eles representam duas formulações diferentes de um mesmo problema de otimização linear, sendo inter-relacionados de maneira específica.\\n\\nProblema Primal\\n\\nO problema primal é a formulação original do problema de otimização linear. Geralmente, é expresso na forma padrão:\\n\\n\\\\[\\\\text{Maximize } \\\\quad c^Tx\\\\]\\n\\\\[\\\\text{sujeito a } \\\\quad Ax \\\\leq b\\\\]\\n\\\\[x \\\\geq 0\\\\]\\n\\nonde:\\n\\n  $c$ é um vetor de coeficientes da função objetivo,\\n  $x$ é o vetor de variáveis de decisão,\\n  $A$ é uma matriz de coeficientes das restrições,\\n  $b$ é o vetor de limites das restrições.\\n\\n\\nA meta é maximizar ou minimizar a função objetivo $c^Tx$ sujeita a um conjunto de restrições lineares.\\n\\nProblema Dual\\n\\nO problema dual é uma formulação alternativa derivada do problema primal usando a teoria de dualidade. Introduz-se multiplicadores de Lagrange para as restrições do problema primal, gerando assim o problema dual. A formulação geral do problema dual é:\\n\\n\\\\[\\\\text{Minimize } \\\\quad b^Ty\\\\]\\n\\\\[\\\\text{sujeito a } \\\\quad A^Ty \\\\geq c\\\\]\\n\\\\[y \\\\geq 0\\\\]\\n\\nonde:\\n\\n  $y$ é o vetor de multiplicadores de Lagrange (ou variáveis duais),\\n  $b$ é o vetor de termos constantes das restrições do primal,\\n  $A^T$ é a matriz transposta de $A$,\\n  $c$ é o vetor de coeficientes da função objetivo do primal.\\n\\n\\nO objetivo do problema dual é encontrar os multiplicadores de Lagrange que minimizam $b^Ty$ sujeito às restrições lineares.\\n\\nRelação de Dualidade\\n\\nA relação fundamental entre os problemas primal e dual é expressa pelo Teorema da Dualidade, que estabelece que o valor ótimo do problema primal é sempre maior ou igual ao valor ótimo do problema dual, e vice-versa. Matematicamente, isso é expresso como:\\n\\n\\\\[\\\\text{Para todo } x \\\\text{ factível no primal e para todo } y \\\\text{ factível no dual, temos } c^Tx \\\\geq b^Ty\\\\]\\n\\nSe ambos os problemas alcançam seus valores ótimos, então há igualdade entre eles. Esta relação é conhecida como dualidade forte.\\n\\nA dualidade não apenas fornece uma maneira de verificar a solução ótima, mas também oferece informações valiosas sobre a sensibilidade do problema às mudanças nos parâmetros e fornece soluções alternativas.\\n\", \"Em 2023 Taylor Swift foi eleita a personalidade do ano, mas há quem diga que 2023 foi mesmo o ano da Inteligência Artificial. E de fato há uma corrida das empresas que ficaram para trás do lançamento do modelo  text-davinci da OpenAI,era um modelo rudimentar comparado aos gpt-turbo-3.5 e o gpt-4 usados hoje, mas fez barulho e mexeu no mercado. Quem se lembra que o lançamento ocorreu quando o mundo ainda estava assutado com a COVID-19 e a Guerra na Ulcrânia, tudo isso acontecia e assustava, mas as atenções e esperanças estavam mesmo para o futuro que já que tinha chegado. O Google lançou o Bard mas não impressionou. A Baidu lançou seu modelo porém restrito ainda a sua área, enquanto a Amazon e a Apple correm atrás do prejuízo. Elon Musk lançou o Grok1, mas até o momento tinha fila de espera para usar. A Apple tenta negociar um acordo milionário para poder usar os artigos da imprensa americana para seu modelo de linguagem2. A Microsoft foi astuta e financiou a OpenAI quando percebeu o potencial do GPT-2 e hoje oferece os modernos modelos como serviço pago ou gratuito.\\n\\nFazendo um chatbot usando o OpenAI\\n\\nFazer um chatbot usando os serviços da OpenAI é simples, usa-se somente UMA chamada de função do módulo da openai em python.\\nCadastro e criação da Secret Key\\nPrimeiro é preciso fazer o cadastro na plataforma de serviço OpenAI API no site https://platform.openai.com/signup. Até o momento eles oferecem créditos para avaliação do serviço e não é preciso cartão de crédito para usar esses créditos. Entretanto a avaliação fica restrista ao modelo gpt-3.5-turbo que não deixa de ser um modelo capaz e poderoso. Se você usa a versão gratuita do site você usa esse modelo.\\n\\nFeito o cadastro é preciso gerar a OpenAI KEY para que se possa usar os serviços.\\n\\n\\n\\nClique em “Create new Secret Key” para criar sua Secret Key, como visto na figura acima.\\n\\nInstalação do módulo de acesso\\nEm seguida é necessário instalar o módulo da openai. Isso pode ser feito pelo PIP ou preferencialmente pelo seu gerenciador de pacotes em sua distribuição Linux.\\npip install openai\\n\\nFazendo sua primeira conversa\\n\\nFinalmente podemos fazer a primeira chamada para a OpenAI. Primeiramente é preciso criar uma instância OpenAI usando sua SECRET_KEY do passo anterior. Para fazer uma requisição usa-se o chat.completions.create como visto no código abaixo:\\n\\n\\n# Importa o módulo OpenAI instalado com pip anteriormente\\nfrom openai import OpenAI\\n# Cria uma instância OpenAI. Utilize aqui sua Secret Key no lugar de SUA_SECRET_KEY ( entre aspas )\\nclient = OpenAI(SUA_SECRET_KEY)\\n\\n# Finalmente fazemos uma requisição ao serviço de chat\\ncompletion = client.chat.completions.create(\\nmodel=\\\"gpt-3.5-turbo\\\",  # Modelo usado.\\n# A personalidade e o texto enviado ao chat.\\nmessages=[\\n    {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"Você é um assistente virtual divertido e bem humorado.\\\"},\\n    {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Qual o sentido da vida?\\\"}\\n]\\n)\\n\\n# E finalmente exibimos a resposta do modelo \\\"gpt-3.5-turbo\\\" a questão \\\"Qual o sentido da vida?\\\"\\nprint(completion.choices[0].message)\\n\\n\\nPersonalizando e embutindo informações\\nBasicamente é só isso. Configura a Key e chama os serviço de complementação de texto completions.create com a personalidade e a mensagem. Fácil não?!\\n\\nAgora é uma boa hora para explicar os roles da requisição. Como se pode ver no código temos uma list com duas dict com as chaves “role” e “content”. Essas informações serão enviadas ao modelo para configurá-lo com a personalidade e informações que se deseja.\\n\\nRole System\\n\\nO role system é o mais forte e determina a personalidade do assistente. Veja alguns exemplos de role system:\\n\\n  “Você é uma IA da empresa Octopus S.A.. A Empresa está localizada no endereço X e tem o telefone Y.”\\n  “Você é um bot do telegram divertido e bem humorado. Sua personalidade é ácida e irônica”\\n  “Você é um assistente virtual no twitch do Gamer Lucão, você adora Minecraft e Playstation 5”\\n\\n\\nEsse role é opcional. Não é preciso enviar nada se não quiser.\\n\\nRole Assistant\\n\\nO role assistant é útil para enviar a conversa anterior e informações relevantes. Em geral usa-se formatação de strings no python para embutir informações e o texto anterior. Veja alguns exemplos:\\n\\nEXPEDIENTE = \\\"estamos abertos até as 18:00hrs\\\" \\n...\\n{\\\"role\\\": \\\"system\\\", \\\"content\\\": F\\\"Hoje é {datetime.datetime.now()} e hoje {EXPEDIENTE}.\\\"}\\n\\nREQ_ANT = \\\"Onde compro o Dipirona?\\\"\\nRESP_ANT = \\\"Olá, Você pode comprar na farmácia ...\\\"\\n...\\n{\\\"role\\\": \\\"system\\\", \\\"content\\\": F\\\"Anteriormente o usuário solicitou '{REQ_ANT}' e você respondeu '{RESP_ANT}'.\\\"}\\n\\n\\nRole User\\n\\nO role user é onde as mensagens do usuário serão inseridas. No exemplo acima foi a mensagem “Qual o sentido da vida?”.\\n\\nLimitações\\n\\nCada requisição é única e não tem memória. Ele não se lembra das requisições anteriores. Para que o modelo saiba o que foi dito anteriormente e ele possa continuar a conversa o histórico deve ser passado no role assistant.\\nTambém há um limite de informações que pode ser colocado nos roles. O conjunto dos roles é chamado contexto.  O limite do contexto é dado em tokens e atualmente é 4096 tokens, mas há modelos que tem 16k tokens.\\n\\nTokens podem ser uma letra ou uma palavra inteira, depende do vocabulário usado pelo modelo. Não conte as letras para verificar o limite de tokens, pois como dito, os tokens podem ser uma letra ou um pedaço de uma palavra ou uma palavra inteira.\\n\\nOs modelos tem controle de conversas tóxicas, ilegais, abusivas e temas sensíveis. Não peça para o modelo contar um conto erótico que dificilmente ele o fará. Também não é possível inventar histórias mentirosas de pessoas ou temas sensíveis. O modelo tem personalidade multicultural, feminista e woke.\\n\\nQuando acabar seus créditos só será possível continuar requisitando com um cartão de crédito onde será cobrado por tokens. Não é muito, você brincando sozinho consumirá menos de \\\\$ 1,00 ou em uso mais intensivo \\\\$ 5,00. Você pode configurar um limite no site para no caso de passar desse valor ele pare de responder as requisições.\\n\\nEmpresas\\n\\nAlgumas observações são importantes quando for usar o chatbot em empresas. Vamos imaginar um cenário onde o chatbot deverá ser usado para consultar um grande banco de dados de produtos e como se percebeu a limitação do contexto (os roles system, assistant e user) não tem como colocar todos os produtos e suas caracteristicas no contexto da requisição, isso é impraticável.\\n\\nPara que uma grande base de dados seja ‘ligada’ ao chatbot deverá ser usado um Langchain ou um Information Extration.\\nO Langchain usa duas camadas. A primeira etapa é a indexação da base de dados que você quer disponibilizar ao chatbot. Nesta etapa documentos, pdfs, textos, planilhas são indexadas por um modelo de embedded que gerará um grande vetor de números de ponto flutuante. Esse vetor representará uma sentença do texto e será armazenado em um banco de dados vetorial ( Vector Database ).\\n\\nQuando o usuário fizer uma requisição a requisição irá novamente para esse modelo embedded que gerará um vetor embedded representando a requisição e o banco de dados será consultado com o valor que mais se aproxima do vetor da requisição.\\nEncontrado a informação, a informação é retornada para o chatbot para ele gerar uma resposta com a informação obtida do banco de dados.\\n\\nExemplo:\\n\\nUm escritório de advocacia quer um chatbot ajudando seus advogados.\\n\\nPrimeira etapa ( pode ser feita somente uma vez ):\\n\\n  Reunir todos os documentos, leis, sentenças e diário oficiais que achar necessário.\\n  Extrair as sentenças ( por exemplo fazendo um .split(\\\".\\\") no texto ).\\n  Gerar um vetor embedded para cada sentença.\\n  Amazenar os vetores embedded em um banco de dados vetorial.\\n\\n\\nSegunda etapa (a cada requisição ):\\n\\n  O usuário digita uma requisição por exemplo “O Sr. Antonio de oliveira tem algum processo cível?”\\n  O modelo embedded gera um vetor com o texto da requisição.\\n  O banco de dados é consultado com esse vetor para achar a sentença mais próxima.\\n  Ele achou por exemplo “Antonio de oliveira x José no nascimento”\\n  A informação é adicionada ao role assistant para o chatbot gerar uma resposta.\\n\\n\\nO Information Extration é diferente este não usa um modelo embedded. Ele extrai a intenção do usuário e as palavras chaves que serão usados para montar diretamente uma requisição SQL ao banco de dados que então retornará a informação a ser inserida nos roles da requisição da resposta.\\n\\nLangchain e Information Extraction são áreas e ferramentas diferentes mas auxiliares do modelos de linguagem. A OpenAI e outras empresas disponibilizam esses serviços pagos.\\n\\n\\n  \\n    \\n      https://grok.x.ai/ &#8617;\\n    \\n    \\n      https://www.nytimes.com/2023/12/22/technology/apple-ai-news-publishers.html &#8617;\\n    \\n  \\n\\n\", \"O problema da mochila ou em inglês “knapsack” é um problema clássico de otimização combinatória.\\n\\nO problema consiste em colocar em uma mochila o maior valor possível de itens com determinada capacidade de peso. A cada item é associado um peso e um valor. O valor pode ser a utilidade ou o preço. Ao ir para o camping espera-se que a mochila seja carregada da maior utilidade de itens possível, enquanto na mochila de um motoqueiro o desejado é transportar o maior valor possível. Dessa forma, o objetivo da otimização é ter o maior valor dentro da mochila, ou seja, maximizar o valor sem ultrapassar o peso. Alguns itens podem ser muito valiosos porém pesados, enquantos alguns itens leves podem ter valor pequeno. Um algoritmo trivial de otimização irá na tentativa e erro colocar itens na mochila até alcançar o peso permitido e ir trocando os itens procurando sempre maximizar o valor dentro da mochila.\\n\\nEsse problema é generalizado para outras aplicações onde o peso pode ser qualquer variável de penalidade e o preço uma variável de maximização. Exemplos não faltam:\\n\\n\\n  Embarcar a maior quantidade de itens possíveis em um caminhão com custo de carga alto\\n  Alocar máquinas de produção visando o menor tempo possível e maior valor produzido\\n  Corte de chapas de madeira, metal, tecidos\\n  Empacotamento\\n  Investimento de Capital\\n\\n\\nCVXPY\\n\\nCVXPY é um framework python para diversos otimizadores com uma linguagem própria e suporte a Numpy.\\n\\nPara instalar o CVXPY use o pip:\\n\\npip install cvxpy\\n\\n\\nUm dos otimizadores disponíveis é o CBC  um otimizador de programação linear inteiro open-source. O CBC pode ser usado em linha de comando sem ser necessário o CVXPY, mas neste caso será necessário aprender sua linguagem de entrada. \\n\\nTambém será necessário instalar o CVXOPT:\\n\\npip install cvxopt\\n\\n\\nEsse problema aparece em diversas áreas como a logística, computação e investimentos.\\n\\nimport cvxpy as cp\\nimport numpy as np\\n\\n\\nDados de entrada do problema\\n\\nValores = np.array([10,13,1,100,45,13,156,76,4,59,97,99])\\nPesos = np.array([50,55,10,5,1,98,34,3,9,3,7,19])\\nCapacidade_Mochila = 100\\n\\n\\nVariaveis de decisão\\n\\nCada Item Xi terá valor 1 se estiver na mochila ou 0 se estiver fora cp.Variable cria uma variável no CVX ( não confunda cp com np ) do tipo boolean do tamanho da quantidade de itens\\n\\nXi = cp.Variable((Valores.size), boolean = True)\\n\\n\\nConstraints do problema\\n\\nA soma total dos pesos dos itens escolhidos por Xi devem ser igual ou menor que a capacidade da mochila                \\n\\nconstraints = [ Xi @ Pesos &lt;= Capacidade_Mochila ]\\n\\n\\nTambem pode ser escrito com o mesmo resultado como:\\n\\nconstraints = [ cp.sum( cp.multiply (Xi, Pesos ) ) &lt;= Capacidade_Mochila ]\\n\\n\\nO Objetivo do problema é maximizar os valores na mochila\\n\\nobjective = cp.Maximize( Xi @ Valores )\\n\\n\\nfinalmente chamamos o solver com verbose para acompanhar \\no progresso e a execução máxima de 1hr\\n\\nprob = cp.Problem(objective, constraints)\\nprob.solve(solver=cp.CBC,verbose=True, maximumSeconds = 1 * 60 * 60) \\nprint(\\\"Status          : \\\", prob.status)\\nprint(\\\"Valor encontrado: \\\", prob.value)\\nprint(\\\"Valor de Xi     : \\\", Xi.value)\\n\\n\\nO problema da mochila tem muitas aplicações práticas principalmente na logística. Imagine uma transportadora que precisa distribuir seus pacotes utilizando vans e caminhões. Cada pacote tem peso, tamanho, localidade, tempo de espera e valor. Um programa de otimização pode ajudar no preenchimento dos caminhões e em aplicações profissionais traçar a rota de distribuição de cada veículo.\\n\\nProgramas de otimização não acham o melhor valor, porque em geral é uma tarefa impossível (o mais correto seria improvável) de se achar, devido a explosão combinatória. Por isso são chamados ‘otimizadores’ pois eles buscam a melhor solução possível, ou seja, uma solução ótima.\\n\", \"Todas as coisas são números.\\nTransformando idéias e sensações em números\\n\\nO mundo não é determinístico para nós. Não dispomos das fórmulas, das regras, das leis, ou a onisciência de saber quando, quanto e se a coisas acontecerão no futuro, entretanto ainda conseguimos perceber que alguns eventos são mais prováveis de ocorrer que outros; sabemos naturalmente que em céu nublado é mais provável de chover do que em céu limpo, que ganhar na loteria é mais improvável que ganhar em um jogo de cartas.\\n\\nPorém confiar somente nas vagas sensações de que algo acontecerá não estava funcionando mais. Os egipicios se esforçavam em desenvolver uma matemática que os ajudassem a evitar a fome ao prever as cheias do Rio Nilo, desde então, o mundo foi percebendo que números são instrumentos confiáveis em representar o mundo. O dinheiro, os soldados, as provisões e as terras eram melhores representados em números. Essa quantificação das idéias chegou nas ‘possibilidades’ para nos ajudar a prever o futuro desconhecido.\\n\\nFoi na busca pelo dinheiro fácil, através dos jogos, que a matemática de tentar prever o futuro avançou e tornou-se o que conhecemos hoje como probabilidade. Já não éra possível confiar na intuição “é agora que eu ganho!”, era necessário um número confiável e preciso para representar as chances de uma vitória.\\n\\nOs jogos em geral são fáceis de se lidar matematicamente, são poucas as variáveis e com valores facilmente acessíveis. Um dado lançado tem 1 variável e 6 valores possíveis, uma carta tirada de um baralho completo será de uma das 52 cartas possíveis. Uma moeda lançada ao acaso terá como resultado a cara ou a coroa. Chamamos esses resultados de eventos de um experimento. Jogar um dado e anotar a face de cima é um experimento, o valor da face é o evento.\\n\\nImagine que sua chance de ficar rico seja o lançar de um dado de 6 lados. Se você acertar o número que aparecer na face de cima após um lançamento você ficará rico. Se o dado tem 6 lados então temos 5 chances de perder e somente 1 possibilidade de ganhar. E se for um dado de 20 lados? Agora são 19 para 1 a possibilidade de perder. E se lhe fosse permitido escolher 5 números no dado de 6? Então neste caso você teria 5 chances de ganhar e 1 de perder. Seria muito azar não ficar rico.\\n\\nNão confunda as chances, possibilidades e tentativas. Há apenas uma tentativa em nosso jogo. Perdeu no primeiro lançamento, acabou o sonho. Se for uma moeda você já abre o champanhe antes mesmo de lançar pois as chances são grandes. Se for na Mega Sena você não dá bola, pois sabe que vai perder.\\n\\n\\nProbabilidade Clássica\\n\\nA probabilidade clássica considera que os eventos tem a mesma probabilidade de ocorrerem, ou seja, são equiprováveis. Se você pensar no lançamento do dado a chance de cair qualquer número é igual para todos. É o mesmo caso do lançamento da moeda no cara e coroa ou na retirada do baralho.\\n\\nO conjunto de valores possíveis que um evento pode ter se chama Espaço Amostral e é abreviado pela letra ‘S’. A tabela a seguir ilustra o espaço amostral dos exemplos mais comuns:\\n\\n\\n  \\n    \\n       \\n      Valores possíveis\\n      Espaço amostral\\n      Número\\n    \\n  \\n  \\n    \\n      Elementos\\n      1,2,3,4,5,6\\n      $S={1,2,3,4,5,6}$\\n      6\\n    \\n    \\n      Moeda\\n      Cara,Coroa\\n      $S={Cara,Coroa}$\\n      2\\n    \\n    \\n      Baralho 52 cartas\\n      Às de espada,Reis de ouro, 2 de copas, …\\n      $S={\\\\text{Às de espada}, …\\\\ \\\\text{Reis de Ouro}}$\\n      52\\n    \\n  \\n\\n\\nNa probabilidade clássica como cada elemento do conjunto do espaço tem a mesma probabilidade de ocorrer e para se obter a probabilidade de algum valor ocorrer dividimos 1 (ou 100%) por todas a combinações possíveis do evento, ou seja, a quantidade de elementos do Espaço amostral.\\nQuanto maior o Espaço Amostral menores as chances de um evento ocorrer, como se vê na tabela a seguir.\\n\\n\\n  \\n    \\n       \\n      Valores possíveis\\n      Espaço amostral\\n      Probabilidade\\n    \\n  \\n  \\n    \\n      Dado\\n      $S={1,2,3,4,5,6}$\\n      6\\n      $P=\\\\frac{1}{6}=0.16…$\\n    \\n    \\n      Moeda\\n      $S={Cara,Coroa}$\\n      2\\n      $P=\\\\frac{1}{2}=0.50$\\n    \\n    \\n      Baralho\\n      $S={\\\\text{Às de espada}, …\\\\ \\\\text{Reis de Ouro}}$\\n      52\\n      $P=\\\\frac{1}{52}=0.019$\\n    \\n  \\n\\n\\nComo se pode ver a probabilidade clássica atribui um número igual para todos os eventos.\\n\\nO problema da probabilidade clássica é assumir que todos os elementos do espaço amostral tem a mesma probabilidade e conhecer o número de elementos do espaço amostral, o que nem sempre ocorre na vida real.\\n\\nProbabilidade frequentista\\n\\nA probabilidade se mostrou útil para outras áreas além dos jogos, porém em outras áreas não é possível calcular a probabilidade de um evento ocorrer com uma simples divisão. Em uma indústria de lampadas como saber qual a probabilidade de uma lampada queimar depois de 1000 horas de uso? O senso comum costuma dizer que “Queima ou não queima, então são 50% de queimar.”. Não, não é assim que funciona.\\n\\nUma outra forma de atribuir probabilidades a eventos é observando diversos experimentos reais e calcular os eventos ocorridos pelo número de observações.\\n\\nExemplos:\\n\\nUma indústria testou 100 lampadas ligadas por 1000 horas e depois de 1000 horas 7 delas queimaram.  Qual a probabilidade que uma lampada dessa indústria queime com 1000 horas de uso?\\n\\nEfetuando os cálculos:\\n\\n$P=\\\\frac{7}{100}=0.07=7\\\\%$\\n\\nHá 7% de chance de uma lampada dessa indústria queimar com 1000 horas de uso.\\n\\nUm cassino estava sob suspeita de fraude e desconfiou-se que seus dados não são confiáveis. Para dirimir as dúvidas foram lançados 50 vezes o dado e obtido os seguintes valores:\\n\\nValor123456\\nExibições988889\\nProbabilidade988889\\n\\nDetermine se o dado é confiável.\\n\\n\\nEfetuando os cálculos:\\n\\n\\n  \\n    \\n      Exibições\\n      9\\n      8\\n      8\\n      8\\n      8\\n      9\\n    \\n    \\n      Probabilidade\\n      $\\\\frac{9}{50}=0.18$\\n      $\\\\frac{8}{50}=0.16$\\n      $\\\\frac{8}{50}=0.16$\\n      $\\\\frac{8}{50}=0.16$\\n      $\\\\frac{8}{50}=0.16$\\n      $\\\\frac{9}{50}=0.18$\\n    \\n  \\n\\n\\nComo a probabilidade de um dado confiável (dado pela probabilidade clássica) é $\\\\frac{1}{6}=0.16$ podemos concluir que o dado é confiável.1\\n\\nA probabilidade frequentista tem a desvantagem de ser necessário realizar os experimentos para a obtenção dos dados o que em alguns casos é impraticável, no exemplo da indústria de lâmpadas seria preciso esperar um bom tempo e destruir as lampadas para a obtenção dos dados. Outro problema é saber quantos experimentos realizar. A teoria diz que o correto é a realização de infinitos testes, algo impossível de se realizar.\\n\\nComparada a anterior, a visão frequentista é mais eficiente em determinar as probabilidades de eventos diferentes do espaço amostral do que simplesmente assumir que os eventos são equiprováveis.\\n\\nProbabilidade subjetiva\\n\\nEnquanto a probabilidade clássica tem total controle sobre o espaço amostral e seus valores e na probabilidade frequentista experimentos são feitos para se obter as probabilidades dos eventos, na probabilidade subjetiva as chances dos eventos ocorrerem é uma opinião pessoal.\\n\\nDe fato é preferível valores precisos da visão frequentista mas em alguns casos não há histórico das observações ou a possibilidade de realizar os experimentos. Suponha um escritório de advocacia que recebeu um processo de um cliente e este pergunta as chances de se ter vitória? Como calcular isso matematicamente? Em geral, o advogado mais experiente faz as melhores previsões.\\n\\nNos cargos de gerência e situações de tomada de decisões um dos atributos mais importantes é perceber corretamente as probabilidades dos eventos. 2\\n\\n\\nCuriosidade:\\n\\nO big data é uma grande quantidade de dados de alguma área registrados em computador. Ao dirigir usando o GPS este registra o trânsito, tempo de viagem, percurso e ocorrências de todas as pessoas que usam ele; essa grande quantidade de dados com o uso de computadores ajuda o GPS a calcular a probabilidade e o tempo de viagem em um dado dia e horário.\\n\\nOs escritórios de advocacia e os tribunais tem registro de milhares de processos que estão sendo fontes de big data para que programas calculem, usando métodos frequentistas e de processamento de linguagem, as chances dos litígios.\\n\\n\\n\\n  \\n    \\n      Para um leitor de nível superior a conclusão não segue o rito normal da inferência estatística. Porém o artigo é direcionado ao nível médio e o leitor pode concordar que intuitivamente é uma conclusão válida. &#8617;\\n    \\n    \\n      Read, D. (2005). Judgment and Choice. In K. Kempf-Leonard (Ed.), Encyclopedia of Social Measurement (pp. 401–407). Elsevier. &#8617;\\n    \\n  \\n\\n\", \"Uma Introdução à Inferência Estatística\\n\\nInferência estatística é uma parte crucial da estatística que nos permite tomar decisões a partir dos dados. É uma ferramenta essencial para analisar uma grande variedade de dados e encontrar respostas a questões específicas.\\n\\nDefinição de Inferência Estatística\\n\\nA Inferência estatística é o processo de usar a análise de dados para deduzir propriedades de uma população ou distribuição de probabilidade. Envolve análise estatística de uma amostra dos dados, gerada pela população. A inferência estatística inclui estimativa de parâmetros e teste de hipóteses.\\n\\nTipos de Inferência Estatística\\n\\nExistem dois tipos principais de inferência estatística: estimação de parâmetros e teste de hipóteses.\\n\\n\\n  Estimação de parâmetros: Isso envolve chegar a uma estimativa da medida de um população a partir de uma amostra. A estimativa pode ser expressa através de um único valor (estimativa pontual) ou um intervalo de valores (estimação intervalar ou intervalo de confiança).\\n\\n\\nPor exemplo, suponha que você queira saber a altura média dos alunos em uma universidade. Para isso, em vez de medir a altura de todos os alunos, você mede a altura de 100 alunos selecionados aleatoriamente (a amostra) e, com base nesses dados, você estima a altura média de todos os alunos (a população).\\n\\n\\n  Teste de hipóteses: Com base na amostra, uma afirmação é feita sobre a população. Essa afirmação (chamada de hipótese) é testada para aceitação ou rejeição. A hipótese de teste é apenas uma suposição sobre a população de onde a amostra foi retirada.\\n\\n\\nPor exemplo, se uma empresa de laticínios afirma que a média do teor de gordura de seu leite é de 3,5%, um consumidor preocupado com a saúde pode pegar uma amostra do leite e testar a hipótese de que o teor de gordura média é realmente esse valor.\\n\\nPor que a Inferência Estatística é Importante?\\n\\nA inferência estatística desempenha um papel vital na análise de dados. Ela fornece métodos para quantificar a incerteza nas conclusões e usar os dados para tomar decisões informadas. É uma ferramenta fundamental para prever tendências futuras, testar teorias e hipóteses, e tomar decisões estratégicas em negócios e pesquisa.\\n\\nExemplo\\n\\nDigamos que uma empresa deseja entender quanto tempo seus funcionários gastam em uma tarefa específica para melhorar a eficácia, e para isso colheu uma amostra de 25 funcionários.\\n\\nDado os tempos em minutos:\\n\\n\\n  \\n    \\n      Tempo em minutos\\n      20, 24, 22, 25, 23, 23, 21, 21, 22, 24, 22, 21, 24, 26, 25, 23, 22, 24, 23, 26, 27, 22, 24, 23, 22\\n    \\n  \\n\\n\\nPrimeiro, calculamos a média e o desvio padrão dessa amostra:\\n\\n  Média $\\\\bar{X} = {\\\\text{soma de todos os tempos} \\\\over \\\\text{número de amostras}}$\\n  Desvio padrão $s = {\\\\sqrt {\\\\sum{(X_i - \\\\bar{X})^2} \\\\over {\\\\text{número de amostras} - 1}}}$\\n\\n\\nCalculando com os valores dados obtemos as seguintes informações:\\n\\n\\n  \\n    \\n      Média $\\\\bar{X}$\\n      23.16\\n    \\n    \\n      Desvio padrão $s$\\n      1.71\\n    \\n  \\n\\n\\nEm seguida, podemos usar essas informações para criar um intervalo de confiança de 95% para o tempo médio que todos os funcionários gastam na tarefa. Supomos que as medidas seguem uma distribuição normal.\\n\\n\\n  $Z_{score}$ para a confiança de $95\\\\% = 1.96$ (Consultando a tabela Z-Score)\\n  Erro padrão $SE = {s \\\\over \\\\sqrt{\\\\text{número de amostras}}}$\\n  Intervalo de confiança = $(\\\\bar{X}) ± Z_{score} \\\\times SE$\\n\\n\\nUma vez que calculamos o intervalo de confiança, podemos dizer que estamos 95% confiantes de que o tempo médio real que todos os funcionários gastam na tarefa está dentro do intervalo de confiança.\\n\\nObserve que as fórmulas acima são simplificações e assumem uma distribuição normal e uma amostra grande o suficiente. Os cálculos exatos podem ser mais complexos dependendo dos aspectos específicos dos dados e do que planejamos inferir.\\n\\nA inferência estatística é uma parte indispensável da estatística e é usada em várias disciplinas que envolvem tomada de decisões baseadas em dados. Também é essencial para traduzir os dados recolhidos em informações compreensíveis e gerenciáveis, e para transformar essas informações em conhecimento para a tomada de decisões.\\n\\nIndependentemente de se tratar de negócios, medicina, engenharia ou ciências sociais, a inferência estatística continuará a ser um componente fundamental na coleta, análise e interpretação de dados, permitindo que as pessoas tomem decisões bem fundamentadas.\\n\", \"Usando Python para ODEs de circuitos elétricos: RL\\n\\nNeste artigo explorarei a solução de circuitos elétricos utilizando Python. A solução analítica será encontrada utilizando SymPy enquanto a solução numérica será obtida com SciPy e Numpy.\\n\\nTratarei apenas do circuito RL da figura abaixo pois encontramos neste tipo de circuito apenas uma derivada. Estudaremos os casos para fontes DC e AC.\\n\\n\\n\\nPara uma fonte DC de 5V o circuito é modelado pela seguinte equação diferencial\\n\\n\\\\[5 = 4700 i{\\\\left(t \\\\right)} + 0.0001 \\\\frac{d}{d t} i{\\\\left(t \\\\right)}\\\\]\\n\\nEsse é um exemplo de Equação Diferencial Ordinária ou abreviadamente ODE cujas soluções podem ser analíticas ou numéricas. A solução analítica é a solução como conhecemos na escola ou a simples solução algébrica através de manipulação dos símbolos onde obteremos no final uma família de funções matemáticas em que podemos calcular o comportamento do circuito. Obter a solução analítica de uma ODE requer conhecimentos de cálculo 1 e 2 lecionados no nível superior, mas utilizando algum CAS (Computer Álgebra System) a solução pode ser encontrada rapidamente.\\n\\nA solução numérica não manipula símbolos, utiliza-se de métodos interativos com tentativa e erros com um certo discernimento de para onde ir em busca da solução. Pode ser feito na mão ou mais adequadamente no computador.\\n\\nRequerimentos\\n\\nComo as soluções serão procuradas com Python precisaremos dos pacotes SymPy, Numpy, Matplotlib e SciPy que podem ser facilmente instalados utilizando o pip:\\n\\npip install sympy numpy matplotlib scipy\\n\\n\\n\\nConheça os pacotes usados\\n\\n    Numpy - Pacote de manipulação de vetores, matrizes e operações matemáticas em geral. Utiliza internamente o OpenBLAS. Praticamente utilizado por todos os outros pacotes inclusive todos os abaixos.\\n    Sympy - Pacote de computação matemática simbólica\\n    Matplotlib - Exibe gráficos.\\n    Scipy - Um grande pacote com diversas utilidades em vários ramos da ciência.\\n\\n\\n\\nEm todos os arquivos os imports necessários e a cabeça do arquivo será este:\\n\\n\\nfrom sympy import *\\nimport numpy as np\\nfrom scipy.integrate import solve_ivp\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\n\\nVersão analítica com SymPy\\n\\nA solução analítica pode ser encontrada utilizando o módulo Sympy. É um módulo promissor, mas ainda está em um nível intermediário de maturidade. Não se compara em poder ao Maxima e ao Mathematica.\\n\\nA solução analítica de uma ODE utilizando o Sympy é encontrada com o comando dsolve.\\n\\n\\nS = 5\\nR = 4700\\nL = 100e-6\\n\\nt = Symbol('t')\\nv = Function('v')(t)\\ni = Function('i')(t)\\n    \\neq = Eq(S,R*i+L*i.diff(t))\\neq\\n\\nO Sympy exibe em formato tex a equação acima como:\\n\\n\\\\[5 = 4700 i{\\\\left(t \\\\right)} + 0.0001 \\\\frac{d}{d t} i{\\\\left(t \\\\right)}\\\\]\\n\\nE como dito a solução analítica é encontrada pelo comando dsolve:\\n\\ndsolve(eq)\\n\\n\\ncuja saída será:\\n\\n\\\\[\\\\displaystyle i{\\\\left(t \\\\right)} = C_{1} e^{- 47000000.0 t} + \\\\frac{1}{940}\\\\]\\n\\nQue é a função de $i$ em $t$ como desejamos. $C_1$ é uma constante que como toda equação diferencial e sistemas físicos que armazenam energia essa constante define a condição inicial da função, oras, temos um indutor no circuito que INICIALMENTE pode ter um campo magnético de valor 0 ou qualquer outro valor que iria interferir no início do circuito. Cabe a nós dizer qual é esse campo. Mas em geral começamos com condições iniciais com corrente zero, ou seja, $i(t=0) = 0$.\\n\\nVersão numérica com SciPy e Numpy\\n\\nSim é muito Py. Pois este é poder do Python: Seus módulos! E as pessoas gostam de homenagear o Python colocando o Py no nome.\\n\\nA solução numérica será encontrada utilizando o comando solve_ivp porém o correto agora é dizermos “as soluções” pois o que obteremos é uma tabela (List) com os valores numéricos de $i$ em $t$ que utilizaremos para visualizar o gráfico do comportamento da corrente no circuito.\\n\\nO solve_ivp precisa que a equação esteja no formato\\n\\n\\\\[{dy(t) \\\\over dt}= ...\\\\]\\n\\nque no nosso caso então seria\\n\\n\\\\[{di(t) \\\\over dt}= ...\\\\]\\n\\ne que esta equação esteja em forma de função Python, dessa forma definimos então a função circuito:\\n\\n\\ndef circuito(t,i):\\n    return (5 -4700*i)/0.0001\\n    \\ntempo_maximo = 0.000001\\nt = np.linspace(0,tempo_maximo,1000)\\nsol = solve_ivp(circuito,[0,tempo_maximo],[0],method='RK45',t_eval=t)\\nplt.plot(sol.t,sol.y[0])\\n\\n\\nO primeiro parâmetro de solve_ivp é nossa função, o segundo o intervalo de tempo que a ODE será integrada e o [0] é o valor inicial e como foi dito antes a corrente no circuito inicialmente é zero, ou seja [0].\\n\\nTempo_maximo é crítico. Se um valor maior que o transitório do circuito for colocado não visualizaremos nada de útil, somente o estado estacionário do circuito. Se for muito pequeno veremos apenas o início do estado transitório que provavelmente será uma reta. Com os valores do programa o seguinte gráfico aparecerá:\\n\\n\\n\\nComo a fonte é contínua o gráfico se apresenta como o esperado. A corrente começa do zero e vai subindo gradativamente até que o indutor seja somente um curto-circuito e a corrente circulante seja a limitada pelo resistor.\\n\\nFonte de tensão senoidal\\n\\nUm circuito de corrente contínua não nos oferece muito, vamos então usar uma fonte de tensão de 1Khz com Vp de 5V.\\n\\nSolução analítica\\n\\n\\nS = 5*sin(t*(2*pi/(1/1000)))\\nR = 4700\\nL = 100e-6\\n\\nt = Symbol('t')\\nv = Function('v')(t)\\ni = Function('i')(t)\\n    \\neq = Eq(S,R*i+L*i.diff(t))\\neq\\ndsolve(eq)\\n\\n\\nA única diferença é a mudança do S com a senoide provida pelo Seno do SymPy sin. As saídas serão então:\\n\\n\\\\[\\\\displaystyle 5 \\\\sin{\\\\left(2000 \\\\pi t \\\\right)} = 4700 i{\\\\left(t \\\\right)} + 0.0001 \\\\frac{d}{d t} i{\\\\left(t \\\\right)}\\\\]\\n\\nE a solução\\n\\n\\\\[\\\\displaystyle i{\\\\left(t \\\\right)} = C_{1} e^{- 47000000.0 t} + 0.00106382976822168 \\\\sin{\\\\left(2000 \\\\pi t \\\\right)} - 1.42217863170866 \\\\cdot 10^{-7} \\\\cos{\\\\left(2000 \\\\pi t \\\\right)}\\\\]\\n\\nBasicamente uma corrente não defasada com 1.06mA. Não entendi o outro cos de valor irrisório. Provavelmente o transitório inicial não seja uma composição pura do exponente e o seno, mas tenha algum componente que deforme a onda (Fourier).\\n\\nSolução numérica\\n\\nJá na solução numérica faremos maiores alterações.\\n\\n\\ndef circuito(t,i):\\n    return (5*np.sin(t*(2*np.pi/0.0001)) -4700*i)/0.0001\\n    \\ntempo_maximo = 0.001\\nt = np.linspace(0,tempo_maximo,10000)\\nsol = solve_ivp(circuito,[0,tempo_maximo],[0],method='RK45',t_eval=t)\\nprint(max(sol.y[0]),min(sol.y[0]))\\n\\nplt.subplots(figsize=(15, 5))\\nplt.subplot(1, 2, 1)\\nplt.plot(sol.t,sol.y[0])\\nplt.subplot(1, 2, 2)\\nplt.plot(t,5*np.sin(t*(2*np.pi/0.0001)))\\n\\n\\nAs alterações, além da fonte, foi o tempo que foi diminuído e exibimos o i máximo e mínimo como mostrado abaixo:\\n\\n\\n  \\n    \\n      i máximo\\n      0.0010661978534370956\\n    \\n    \\n      i minimo\\n      -0.0010652848773317844\\n    \\n  \\n\\n\\nNos gráficos abaixo o primeiro é a corrente do circuito encontrada pela solução numérica e o outro a tensão da fonte.\\n\\n\\n\\nOs valores mínimos e máximos mostram uma corrente de 1.06mA que confere com a solução analítica obtida anteriormente.\\n\\nFalstad\\n\\nVamos conferir com o simulador de circuitos do Falstad? Que aliás usa de muita solução numérica para simular o circuito.\\n\\n\\n\\nComo se pode ver no osciloscópio Fonte CA o Max=1.064mA novamente confere com os cálculos.\\n\\nEspero que tenham gostado. Em breve novos posts!\\n\\n\", \"O que são Filtros FIR?\\n\\nOs Filtros de Resposta ao Impulso Finita, ou FIR (do inglês Finite Impulse Response), são uma classe de filtros digitais amplamente utilizados em processamento de sinais. Ao contrário dos Filtros de Resposta ao Impulso Infinita (IIR), os FIR têm uma resposta ao impulso de duração finita, o que os torna mais simples de entender e implementar.\\n\\nOs filtros FIR são frequentemente utilizados em uma variedade de aplicações, como processamento de áudio, comunicação digital e processamento de imagens. Sua característica finita permite uma análise mais fácil de seu comportamento e uma implementação mais robusta em muitas situações.\\n\\nEstrutura Básica dos Filtros FIR\\n\\nA estrutura básica de um filtro FIR consiste em uma soma ponderada de amostras de entrada, cada uma multiplicada por um coeficiente específico. Matematicamente, a saída $y[n]$ de um filtro FIR pode ser expressa como a soma ponderada das amostras de entrada $x[n]$ e seus coeficientes associados $h[k]$:\\n\\n\\\\[ y[n] = \\\\sum_{k=0}^{N-1} h[k] \\\\cdot x[n-k] \\\\]\\n\\nOnde:\\n\\n  $N$ é a ordem do filtro (o número total de coeficientes),\\n  $x[n]$ é a amostra de entrada no instante $n$,\\n  $h[k]$ são os coeficientes do filtro.\\n\\n\\nExemplo de Cálculo de Coeficientes FIR\\n\\nPara entender melhor como os coeficientes de um filtro FIR são calculados, consideremos um exemplo prático. Vamos projetar um filtro passa-baixa com uma frequência de corte normalizada de 0,2 em um sistema com frequência de amostragem normalizada de 1.\\n\\n\\n  \\n    Determine a ordem do filtro (N):\\n  A ordem do filtro depende da complexidade desejada. Para este exemplo, escolheremos uma ordem $N = 15$.\\n  \\n  \\n    Calcule a frequência de corte digital (wc):\\n  A frequência de corte digital é obtida multiplicando a frequência de corte desejada pela frequência de amostragem. Portanto, $wc = 0,2 \\\\times 1 = 0,2$.\\n  \\n  \\n    Calcule os coeficientes (h[k]):\\n  Utilizaremos a fórmula para um filtro passa-baixa ideal:\\n\\n    $ h[k] = \\\\frac{\\\\sin(\\\\pi \\\\cdot k \\\\cdot wc)}{\\\\pi \\\\cdot k} $\\n\\n    Para $k = 0$, temos que $h[0] = 2 \\\\cdot wc$. Para $k$ diferente de zero, aplicamos a fórmula.\\n\\n    Vamos calcular os coeficientes para $k = 1$ até $N-1 = 14$.\\n\\n    $ h[k] = \\\\frac{\\\\sin(\\\\pi \\\\cdot k \\\\cdot 0,2)}{\\\\pi \\\\cdot k} $\\n\\n    Portanto, os coeficientes seriam:\\n  \\\\[ h[0] = 0,4 \\\\]\\n  \\\\[ h[k] = \\\\frac{\\\\sin(\\\\pi \\\\cdot k \\\\cdot 0,2)}{\\\\pi \\\\cdot k} \\\\quad \\\\text{para } k = 1 \\\\text{ até } 14 \\\\]\\n  \\n  \\n    Normalização dos Coeficientes:\\n  É comum normalizar os coeficientes de modo que a soma dos quadrados seja igual a 1.\\n\\n\\\\[h[k]_{\\\\text{normalizado}} = \\\\frac{h[k]}{\\\\sqrt{\\\\sum_{k=0}^{N-1} h[k]^2}}\\\\]\\n\\n    Isso garante que a amplitude do sinal não seja afetada durante o processo de filtragem.\\n  \\n\\n\\nOs filtros FIR são uma ferramenta poderosa no processamento de sinais digitais. Com uma compreensão básica de sua estrutura e uma abordagem prática para calcular os coeficientes, é possível projetar filtros personalizados para atender às necessidades específicas de uma aplicação. Experimentar com diferentes ordens e frequências de corte permite ajustar o desempenho do filtro de acordo com os requisitos do sistema.\\n\", \"1 Tempos atrás (2013), com humor, um “surto de honestidade” entre os cientistas percorreu o twitter com a hashtag #overlyhonestmethods. Naquela semana os cientistas fugiram da impessoalidade e frieza dos artigos científicos e foram honestos com o público expondo como realmente suas descobertas aconteceram.\\n\\nTemos a sensação ao ler esses artigos que toda descoberta seja perfeita, siga um rito rigoroso e metódico e dessa forma continuamos confiantes na ciência. Mas nem sempre é assim, destaco a descoberta acidental da Penicilina que revolucionou a medicina no tratamento das infecções: De um acidente de laboratório descobriu-se os antibióticos, então, depois do êxtase da descoberta restava explicar o porque, o como e para que; cansativo não?\\n\\nPorque não se lembrar do técnico de manutenção de uma máquina que deu-lhe um chute voltando a funcionar e dado por seu turno acabado tão cedo ficou feliz, porém quando seu chefe lhe pede um relatório dos motivos, sua alegria se vai pois terá que realmente desmontar a máquina e pesquisar o componente defeituoso.\\n\\nO conhecimento de um fenômeno, ou descoberta pode ser acidental, criativo ou porque não vir dos Céusm porém o Conhecimento Científico exige que se explique o porquê, ou pelo menos o como para que outros possam reproduzir e testar a descoberta. Da mesma forma a investigação de um crime exige a minuciosa enumeração das causalidades que não devem deixar dúvidas de sua virtual reprodução.\\n\\nEntretanto o Conhecimento Filosófico não serve a ciência, aliás não serve a ninguém, ele somente duvida, não crê e indaga as verdades.\\n\\n- Uau! A Penicilina é uma grande descoberta! Muitas vidas foram salvas!\\n\\nMas ela cura? O que é a cura? Seus efeitos colaterais não seriam uma nova doença? Eu realmente estou saudável? Eu existo? Você existe?\\n\\nCertamente o técnico não pode se valer desses questionamentos com seu chefe sobre perigo de loucura e rua, mas terá que escrever um relatório no Word dos motivos do defeito e criar um procedimento reproduzível de como se precaver desse fenômeno (o defeito) indesejado.\\n\\nQuem quiser saber mais sobre a crise de honestidade dos cientistas\\n\\n\\n  \\n    \\n      Photo by British Library on Unsplash Photo by British Library on Unsplash &#8617;\\n    \\n  \\n\\n\"]",
    "excerpt" : "[\"Resumo e Explicação da Funcionalidade de tohost e fromhost no Spike e em Ambientes RISC-V\\n\\n\", \"\\nQuadrix - 2024 - CRQ - 12ª Região (GO, TO e DF) - Agente Fiscal - 2024Bárbara é proprietária de uma coleção de pedras preciosas, composta de 5 rubis e de 5 esmeraldas, sendo cada uma única e distintiva. Recentemente, Bárbara adquiriu um elegante porta‑joias com 10 compartimentos dispostos em fileira para exibir suas preciosidades. Bárbara, então, pretende alocar uma joia em cada espaço.\\nCom base nessa situação hipotética, julgue o item.Se Bárbara decidir alocar suas joias de forma aleatória, a probabilidade de que todos os rubis fiquem juntos é de 1 em 42.\\n\\nCerto\\nErrado\\n\\n\\n\", \"Entendendo os Padrões NEMA para Motores Elétricos\\n\\n\", \"Bricando com equações diferenciais pelo método RK4\\n\\n\", \"\\n\", \"\\n\\n\\n\", \"\\n\\n\\n\", \"Órgãos Antigos dos Anos 70: Geradores e Divisores de Oitavas\\n\\n\", \"Tokenização\\n\\n\", \"Se você tem um leitor OBD2 em inglês essa lista pode te ajudar a desvendar as siglas na leitura.\\n\\n\", \"Os problemas primal e dual estão intrinsecamente ligados na teoria da dualidade em programação linear. Eles representam duas formulações diferentes de um mesmo problema de otimização linear, sendo inter-relacionados de maneira específica.\\n\\n\", \"Em 2023 Taylor Swift foi eleita a personalidade do ano, mas há quem diga que 2023 foi mesmo o ano da Inteligência Artificial. E de fato há uma corrida das empresas que ficaram para trás do lançamento do modelo  text-davinci da OpenAI,era um modelo rudimentar comparado aos gpt-turbo-3.5 e o gpt-4 usados hoje, mas fez barulho e mexeu no mercado. Quem se lembra que o lançamento ocorreu quando o mundo ainda estava assutado com a COVID-19 e a Guerra na Ulcrânia, tudo isso acontecia e assustava, mas as atenções e esperanças estavam mesmo para o futuro que já que tinha chegado. O Google lançou o Bard mas não impressionou. A Baidu lançou seu modelo porém restrito ainda a sua área, enquanto a Amazon e a Apple correm atrás do prejuízo. Elon Musk lançou o Grok1, mas até o momento tinha fila de espera para usar. A Apple tenta negociar um acordo milionário para poder usar os artigos da imprensa americana para seu modelo de linguagem2. A Microsoft foi astuta e financiou a OpenAI quando percebeu o potencial do GPT-2 e hoje oferece os modernos modelos como serviço pago ou gratuito.\\n\\n\\n  \\n    \\n      https://grok.x.ai/ &#8617;\\n    \\n    \\n      https://www.nytimes.com/2023/12/22/technology/apple-ai-news-publishers.html &#8617;\\n    \\n  \\n\\n\", \"O problema da mochila ou em inglês “knapsack” é um problema clássico de otimização combinatória.\\n\\n\", \"Todas as coisas são números.\\nTransformando idéias e sensações em números\\n\\n\", \"Uma Introdução à Inferência Estatística\\n\\n\", \"Usando Python para ODEs de circuitos elétricos: RL\\n\\n\", \"O que são Filtros FIR?\\n\\n\", \"1 Tempos atrás (2013), com humor, um “surto de honestidade” entre os cientistas percorreu o twitter com a hashtag #overlyhonestmethods. Naquela semana os cientistas fugiram da impessoalidade e frieza dos artigos científicos e foram honestos com o público expondo como realmente suas descobertas aconteceram.\\n\\n\\n  \\n    \\n      Photo by British Library on Unsplash Photo by British Library on Unsplash &#8617;\\n    \\n  \\n\\n\"]",
    "categories" : [["programação"],["educação"],["automação"],["aplicadas"],["app"],["app"],["app"],["eletronica"],["aplicadas"],["eletronica"],["aplicadas"],["python"],["aplicadas"],["educação"],["aplicadas"],["eletrônica"],["eletrônica"],["ciências"]],
    "featured" : [false,true,true,true,false,false,false,true,true,false,false,true,false,true,false,true,false,false],
    "tags" : [["riscv"],["matemática","probabilidade"],["motores passo","cnc","impressão 3d"],["matemática","javascript"],["auto","obd2","ecu"],["eletrônica","resistores","código de cores"],["eletrônica","capacitores","código de cores"],["música eletrônica","sintetizadores"],["python","IA","tokenizers","llm"],["obd2"],["programação linear","otimização","pesquisa operacional"],["AI","ChatGPT","python"],["python","otimização","CVXPY"],["matemática","probabilidade"],["matemática","estatística"],["eletrônica","python","circuitos elétricos"],["eletrônica","processamento de sinais","filtros"],["filosofia","ciências"]]
}